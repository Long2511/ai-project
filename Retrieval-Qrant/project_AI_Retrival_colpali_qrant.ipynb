{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPEMPPJ95o34EL/kR9pyoyv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\", force_remount=True)\n","    print(\"[colab] Drive mounted at /content/drive\")\n","except Exception as e:\n","    print(\"[note] Not in Colab or Drive mount failed:\", e)"],"metadata":{"id":"XUaT64ZyEU4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WatXcgE4qWFP"},"outputs":[],"source":["import sys, subprocess, os\n","def sh(cmd): print(cmd); subprocess.run(cmd, shell=True, check=True)\n","\n","# CUDA 12.1-compatible torch for Colab\n","!python3 -m pip -q install --index-url https://download.pytorch.org/whl/cu121 \"torch==2.5.1\" \"torchaudio==2.5.1\" \"torchvision==0.20.1\"\n","# Core libs: ColPali, transformers, qdrant-client (multi-vector), OCR, PDF\n","!python3 -m pip -q install \"transformers>=4.53.1,<4.54.0\" colpali-engine==0.3.12 \"qdrant-client>=1.7.3,<2\" accelerate sentencepiece pdf2image pytesseract\n","# System deps for OCR/PDF\n","sh('apt-get -y update && apt-get -y install tesseract-ocr poppler-utils')"]},{"cell_type":"code","source":["SOURCE_DIR         = \"/content/drive/MyDrive/Project-AI/PDF-Data\"\n","MODEL_NAME         = \"vidore/colpali-v1.2-hf\"\n","\n","# Outputs\n","PAGES_JSONL        = \"/content/clinical_cases_index.jsonl\"\n","CASES_JSONL        = \"/content/clinical_cases_cases.jsonl\"\n","STRUCT_JSONL       = \"/content/clinical_cases_cases_structured.jsonl\"\n","SFT_EXTRACT_JSONL  = \"/content/clinical_cases_extract_sft.jsonl\"\n","SFT_DX_JSONL       = \"/content/clinical_cases_dx_sft.jsonl\"\n","\n","# Qdrant collections\n","COLLECTION_PAGES   = \"tropical_cases_colpali_pages\"\n","COLLECTION_CASES   = \"tropical_cases_colpali_cases\"\n","VECTOR_SIZE        = 128  # ColPali subvector dim\n","VECTOR_NAME = \"default\"\n","\n","# Toggles\n","INDEX_PAGES        = True\n","INDEX_CASES        = True\n","ENABLE_OCR         = True\n","ENABLE_PDF         = True\n","BATCH              = 2      # embedding batch size\n","MAX_FILES          = None   # set small int to smoke-test\n","\n","# Qdrant remote (REST-only)\n","QDRANT_HOST        = \"165.22.56.15\"\n","QDRANT_PORT        = 6333    # QRPcQDRANT_API_KEY     = os.getenv(\"QDRANT_API_KEY\") or None\n","QDRANT_TIMEOUT     = 1200.0  # large to be safe\n","UPSERT_BATCH       = 12      # points per upsert() call; keep small for reliability\n","UPSERT_MAX_RETRIES = 6"],"metadata":{"id":"GSmh86eYroIl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re, json, glob, hashlib, io, time\n","from typing import List, Dict, Any, Tuple\n","from PIL import Image\n","from tqdm import tqdm\n","import torch\n","from collections import defaultdict\n","from typing import Optional\n","\n","\n","from transformers import ColPaliForRetrieval, ColPaliProcessor\n","from qdrant_client import QdrantClient, models\n","\n","try:\n","    import pytesseract\n","except Exception as e:\n","    print(\"[warn] OCR disabled:\", e); ENABLE_OCR=False\n","\n","try:\n","    from pdf2image import convert_from_path\n","except Exception as e:\n","    print(\"[warn] PDFâ†’image disabled:\", e); ENABLE_PDF=False"],"metadata":{"id":"aw_FberUrwAc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_colpali(device=None):\n","    device = device or (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"[env] device={device}\\n[env] loading ColPaliâ€¦\")\n","\n","    model = ColPaliForRetrieval.from_pretrained(\n","        MODEL_NAME,\n","        torch_dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32),\n","    ).eval()\n","    model.to(device)\n","\n","    processor = ColPaliProcessor.from_pretrained(MODEL_NAME)\n","    print(\"[env] ColPali loaded.\")\n","    return model, processor, device\n","\n","@torch.no_grad()\n","def embed_images(model, processor, device, pil_images: List[Image.Image]):\n","    batch = processor(images=pil_images).to(device)\n","    emb = model(**batch).embeddings  # [B, N, 128] multivectors\n","    return [e.to(\"cpu\").float().tolist() for e in emb]  # List[List[List[float]]]\n","\n","@torch.no_grad()\n","def embed_queries(model, processor, device, queries: List[str]):\n","    batch = processor(text=queries).to(device)\n","    emb = model(**batch).embeddings\n","    return [e.to(\"cpu\").float().tolist() for e in emb]"],"metadata":{"id":"1xwRwnd42Lm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def connect_qdrant_rest():\n","    url = f\"http://{QDRANT_HOST}:{QDRANT_PORT}\"\n","    client = QdrantClient(\n","        url=url,\n","        api_key=None,\n","        timeout=QDRANT_TIMEOUT,\n","        prefer_grpc=False,  # <- HARD disable gRPC\n","    )\n","    # sanity call\n","    client.get_collections()\n","    print(f\"[qdrant] connected (REST-only): {url}\")\n","    return client\n","\n","def ensure_collection(client: QdrantClient, name: str):\n","    try:\n","        exists = client.collection_exists(name)\n","    except Exception:\n","        # REST fallback path if needed\n","        try:\n","            client.http.collections_api.get_collection(name)\n","            exists = True\n","        except Exception:\n","            exists = False\n","\n","    if not exists:\n","        print(f\"[qdrant] creating collection: {name}\")\n","        client.create_collection(\n","            collection_name=name,\n","            vectors_config={\n","                VECTOR_NAME: models.VectorParams(\n","                    size=VECTOR_SIZE,\n","                    distance=models.Distance.COSINE,\n","                    multivector_config=models.MultiVectorConfig(\n","                        comparator=models.MultiVectorComparator.MAX_SIM\n","                    ),\n","                )\n","            },\n","            on_disk_payload=True,\n","            hnsw_config=models.HnswConfigDiff(m=32, ef_construct=128),\n","            optimizers_config=models.OptimizersConfigDiff(default_segment_number=2),\n","        )\n","    else:\n","        print(f\"[qdrant] collection exists: {name}\")\n","\n","# Deterministic 63-bit IDs (so re-runs are true updates)\n","def stable_point_id(key: str) -> int:\n","    h = hashlib.sha1(key.encode(\"utf-8\")).hexdigest()\n","    return int(h[:15], 16) & ((1<<63)-1)"],"metadata":{"id":"gjDrZi7N2Zep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["client = connect_qdrant_rest()\n","model, processor, device = load_colpali()\n","\n"],"metadata":{"id":"rZyJETwH3KLd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Retrival with cases-level"],"metadata":{"id":"0hiR7kmQZfgH"}},{"cell_type":"code","source":["info = client.get_collection(COLLECTION_CASES)\n","print(info)  # xem pháº§n vector params / tÃªn\n"],"metadata":{"id":"QitGoiL59G_5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###"],"metadata":{"id":"bpDlIrAWarPo"}},{"cell_type":"code","source":["def encode_query_colpali(q: str):\n","\n","    subvecs = embed_queries(model, processor, device, [q])[0]\n","\n","    return [ (sv.tolist() if hasattr(sv, \"tolist\") else list(sv)) for sv in subvecs ]\n","\n","\n","\n","def search_cases_MAX(question: str, k: int = 5, filter_modality: Optional[str] = None):\n","    subvecs = encode_query_colpali(question)\n","\n","    qfilter = None\n","    if filter_modality:\n","        qfilter = models.Filter(must=[\n","            models.FieldCondition(key=\"modality\", match=models.MatchValue(value=filter_modality))\n","        ])\n","\n","    agg = {}\n","\n","    for v in subvecs:\n","\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=k * 4,\n","            with_payload=True,\n","            query_filter=qfilter\n","        )\n","        for h in hits:\n","            pid = h.id\n","            sc  = h.score\n","            pl  = h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","\n","    class Hit:\n","        def __init__(self, _id, score, payload):\n","            self.id = _id; self.score = score; self.payload = payload\n","    return [Hit(_id=i, score=sc, payload=pl) for i,(sc,pl) in ranked]\n","\n","def pretty_print_case_hits(hits):\n","    print()\n","    for i, hit in enumerate(hits, 1):\n","        p = hit.payload or {}\n","        title = p.get(\"case_title\", \"N/A\")\n","        cid   = p.get(\"case_id\", \"N/A\")\n","        n_pg  = p.get(\"n_pages\", \"N/A\")\n","        paths = p.get(\"page_paths\", []) or []\n","        print(f\"Rank {i:>2} | Score: {hit.score:.3f}\")\n","        print(f\"  Case ID    : {cid}\")\n","        print(f\"  Case Title : {title}\")\n","        print(f\"  #Pages     : {n_pg}\")\n","        if paths: print(f\"  First page : {paths[0]}\")\n","        print(\"-\"*88)\n","\n","\n","question = \"What are the symptoms and nursing precautions for Ebola virus infection?\"\n","hits = search_cases_MAX(question, k=5, filter_modality=\"case_multivector\")\n","print(f\"ðŸ”Ž Query: {question}\")\n","pretty_print_case_hits(hits)"],"metadata":{"id":"nu11PhC7-XjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import re\n","\n","needles = [r\"ebola\", r\"hemorrh\", r\"haemorrh\", r\"sudan\"]\n","rx = re.compile(\"|\".join(needles), flags=re.I)\n","\n","titles = []\n","cursor = None\n","while True:\n","    recs, cursor = client.scroll(\n","        collection_name=COLLECTION_CASES,\n","        with_payload=True,\n","        limit=200,\n","        offset=cursor\n","    )\n","    if not recs:\n","        break\n","    for r in recs:\n","        title = (r.payload or {}).get(\"case_title\",\"\")\n","        if rx.search(title):\n","            titles.append(title)\n","    if cursor is None:\n","        break\n","\n","print(f\"Found {len(titles)} titles matching {needles}:\")\n","for t in titles[:20]:\n","    print(\"-\", t)\n"],"metadata":{"id":"b9u-cnuNTbNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","records, next_offset = client.scroll(\n","    collection_name=\"tropical_cases_colpali_cases\",\n","    with_payload=True,\n","    with_vectors=True,\n","    limit=1\n",")\n","\n","assert records, \"There are no points in the collection\"\n","\n","point = records[0]\n","\n","\n","vec_field = getattr(point, \"vector\", None)\n","if vec_field is None:\n","    vec_field = getattr(point, \"vectors\", None)\n","\n","print(\"Point type:\", type(point))\n","print(\"Vector field type:\", type(vec_field))\n","\n","\n","if isinstance(vec_field, list):\n","    if vec_field and isinstance(vec_field[0], list):\n","        print(f\"âœ… Unnamed MULTI-VECTOR | num_subvectors={len(vec_field)} | dim={len(vec_field[0])}\")\n","    else:\n","        print(f\"âœ… SINGLE vector | dim={len(vec_field)}\")\n","elif isinstance(vec_field, dict):\n","    print(\"âœ… Named vectors map:\")\n","    for name, v in vec_field.items():\n","        if isinstance(v, list) and v and isinstance(v[0], list):\n","            print(f\"  - {name}: MULTI-VECTOR | num_subvectors={len(v)} | dim={len(v[0])}\")\n","        else:\n","            print(f\"  - {name}: SINGLE vector | dim={len(v)}\")\n","else:\n","    print(\"Vector structure is unclear; print it to inspec\")\n","    print(vec_field)\n"],"metadata":{"id":"mn1xn98r_lUl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode_query_topk(q: str, top_m: int = 16):\n","    subvecs = embed_queries(model, processor, device, [q])[0]\n","\n","    return subvecs[:top_m]\n","\n","def search_cases_MAX(question: str, k=5, filter_modality=None, m_query=16, per_subvec_limit=20):\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","\n","    qfilter = None\n","    if filter_modality:\n","        qfilter = models.Filter(must=[models.FieldCondition(\n","            key=\"modality\", match=models.MatchValue(value=filter_modality)\n","        )])\n","\n","    agg = {}\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter\n","        )\n","        for h in hits:\n","            pid, sc = h.id, h.score\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, h.payload)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","    return [type(\"Hit\", (), {\"id\": i, \"score\": sc, \"payload\": pl}) for i,(sc,pl) in ranked]\n"],"metadata":{"id":"EtjhHBS-AM6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"What are the symptoms and nursing precautions for Ebola virus infection?\"\n","hits = search_cases_MAX(question, k=5, filter_modality=\"case_multivector\")\n","for i, h in enumerate(hits, 1):\n","    p = h.payload or {}\n","    print(f\"Rank {i} | score={h.score:.3f}\")\n","    print(\"  Case ID   :\", p.get(\"case_id\"))\n","    print(\"  Title     :\", p.get(\"case_title\"))\n","    print(\"  #Pages    :\", p.get(\"n_pages\"))\n","    paths = p.get(\"page_paths\") or []\n","    if paths: print(\"  FirstPage :\", paths[0])\n","    print(\"-\"*80)\n"],"metadata":{"id":"RvQVMSVWAmdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","from IPython.display import display\n","\n","def show_first_pages(hits, top=5):\n","    for h in hits[:top]:\n","        p = h.payload or {}\n","        paths = p.get(\"page_paths\") or []\n","        if not paths:\n","            continue\n","        try:\n","            print(f\"[Case {p.get('case_id')}] {p.get('case_title')}\")\n","            display(Image.open(paths[0]))\n","        except Exception as e:\n","            print(\"Cannot open:\", paths[0], \"->\", e)\n","\n","show_first_pages(hits, top=3)\n"],"metadata":{"id":"NE0ySjsCEK21"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","candidates = [1, 44]\n","\n","def search_cases_MAX_restrict(question: str, candidate_case_ids, k=5, m_query=16, per_subvec_limit=40, hnsw_ef=256):\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    params = models.SearchParams(hnsw_ef=hnsw_ef)\n","\n","    qfilter = models.Filter(should=[\n","        models.FieldCondition(key=\"case_id\", match=models.MatchValue(value=int(cid)))\n","        for cid in candidate_case_ids\n","    ])\n","\n","    agg = {}\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","    return [type(\"Hit\", (), {\"id\": i, \"score\": sc, \"payload\": pl}) for i,(sc,pl) in ranked]\n","\n","question = \"Ebola viral hemorrhagic fever with bleeding and shock; nursing isolation and PPE precautions; patient from Sudan.\"\n","hits = search_cases_MAX_restrict(question, candidates, k=5, m_query=12, per_subvec_limit=50, hnsw_ef=256)\n","for i, h in enumerate(hits, 1):\n","    p = h.payload or {}\n","    print(f\"Rank {i} | score={h.score:.3f} | case_id={p.get('case_id')} | {p.get('case_title')}\")\n"],"metadata":{"id":"fY-O3xw9FWpO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Retrival with page-level and then combine with case level for getting case"],"metadata":{"id":"9UHbvOXzbJm1"}},{"cell_type":"markdown","source":["## config"],"metadata":{"id":"0tCbFEH7geYV"}},{"cell_type":"code","source":["\n","\n","# Suggested default parameters (tune as needed)\n","DEFAULTS = dict(\n","    page_m_query=12,               # #sub-vectors from ColPali for page-level\n","    page_per_subvec_limit=120,     # breadth per sub-vector at page-level\n","    page_hnsw_ef=512,              # higher â†’ better recall (slower)\n","    case_m_query=12,               # #sub-vectors from ColPali for case-level\n","    case_per_subvec_limit=80,      # breadth per sub-vector at case-level\n","    case_hnsw_ef=512,              # higher â†’ better recall (slower)\n","    candidate_cases=120,           # how many candidate cases from page hits\n","    top_pages_show=12,             # how many top evidence pages to print\n","    top_cases_show=5,              # final top-k cases\n","    pages_per_case_for_context=2,  # #evidence pages per case to OCR for LLM\n","    max_context_chars=4000         # char budget for LLM context (roughly ~600â€“900 tokens)\n",")\n","\n","\n","# Optional sanity checks\n","try:\n","    info_pages = client.get_collection(COLLECTION_PAGES)\n","    info_cases = client.get_collection(COLLECTION_CASES)\n","    print(\"[ok] Qdrant connected\")\n","    print(\"[ok] pages:\", info_pages.status, \"| cases:\", info_cases.status)\n","except Exception as e:\n","    print(\"[warn]\", e)\n"],"metadata":{"id":"P5Sy6KXVbcG-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Helpers (encoder + pretty printers)"],"metadata":{"id":"fg5HybzngiRz"}},{"cell_type":"code","source":["\n","\n","def encode_query_topk(q: str, top_m: int = 12):\n","    \"\"\"Encode a query with ColPali into a multi-vector and keep top_m sub-vectors to reduce noise and latency.\"\"\"\n","    subvecs = embed_queries(model, processor, device, [q])[0]\n","    return subvecs[:top_m]\n","\n","def print_page_hits(hits, title=None, limit=None):\n","    \"\"\"Pretty-print page-level hits.\"\"\"\n","    if title: print(title)\n","    for i, h in enumerate(hits[:(limit or len(hits))], 1):\n","        p = h.payload or {}\n","        print(f\"Rank {i:>2} | score={h.score:.3f} | case_id={p.get('case_id')} | page={p.get('page_number')} | {p.get('path')}\")\n","\n","def print_case_hits(hits, title=None):\n","    \"\"\"Pretty-print case-level hits.\"\"\"\n","    if title: print(title)\n","    for i, h in enumerate(hits, 1):\n","        p = h.payload or {}\n","        print(f\"Rank {i:>2} | score={h.score:.3f} | case_id={p.get('case_id')} | {p.get('case_title')}\")\n"],"metadata":{"id":"uFFO172PbrT0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Page-level retrieval (MAX fusion over multivectors)"],"metadata":{"id":"K9Ae5Uz1gzsp"}},{"cell_type":"code","source":["def search_pages_MAX(\n","    question: str,\n","    k_pages: int = 100,\n","    m_query: int = DEFAULTS[\"page_m_query\"],\n","    per_subvec_limit: int = DEFAULTS[\"page_per_subvec_limit\"],\n","    hnsw_ef: int = DEFAULTS[\"page_hnsw_ef\"]\n","):\n","    \"\"\"\n","    Page-level retrieval with ColPali multivectors on a MAX-SIM collection.\n","    We query each sub-vector separately, take top-N page hits per sub-vector, and\n","    aggregate with MAX score per page (mimicking MAX comparator behavior).\n","    \"\"\"\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    try:\n","        params = models.SearchParams(hnsw_ef=hnsw_ef)  # may be ignored by older clients\n","    except Exception:\n","        params = None\n","\n","    agg = {}  # page_point_id -> (max_score, payload)\n","    for v in subvecs:\n","        hits = client.search(  # deprecated warning is fine; your client still supports it\n","            collection_name=COLLECTION_PAGES,\n","            query_vector=v,    # unnamed vector for unnamed multivector collections\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k_pages]\n","    return [type(\"Hit\", (), {\"id\": pid, \"score\": sc, \"payload\": pl}) for pid,(sc,pl) in ranked]\n"],"metadata":{"id":"NR2iovdrcHkf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Aggregate pages â†’ cases (PAGEâ†’CASE) + (optional) Fusion"],"metadata":{"id":"JLSEPjaMg04x"}},{"cell_type":"code","source":["def pages_to_case_candidates(hits_pages, top_cases=DEFAULTS[\"candidate_cases\"]):\n","    \"\"\"\n","    From page hits, compute candidate cases by taking the best page score per case,\n","    then keep top-N cases as candidates for a second-stage (optional) case-level search.\n","    \"\"\"\n","    case_best = {}\n","    for h in hits_pages:\n","        p = h.payload or {}\n","        cid = p.get(\"case_id\")\n","        if cid is None:\n","            continue\n","        ttl = p.get(\"case_title\", \"\")\n","        if cid not in case_best or h.score > case_best[cid][0]:\n","            case_best[cid] = (h.score, ttl)\n","    ranked = sorted(case_best.items(), key=lambda kv: kv[1][0], reverse=True)[:top_cases]\n","    return [int(cid) for cid, _ in ranked]\n","\n","def rank_cases_from_pages(hits_pages, top_k=DEFAULTS[\"top_cases_show\"]):\n","    \"\"\"\n","    Pure PAGEâ†’CASE ranking: score(case) = max_page_score(case).\n","    This preserves page evidenceâ€”recommended for clinical QA with citations.\n","    \"\"\"\n","    case_best = {}\n","    for h in hits_pages:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        ttl = p.get(\"case_title\", \"\")\n","        if cid not in case_best or h.score > case_best[cid][0]:\n","            case_best[cid] = (h.score, ttl)\n","    ranked = sorted(case_best.items(), key=lambda kv: kv[1][0], reverse=True)[:top_k]\n","    return [type(\"Hit\", (), {\"id\": cid, \"score\": sc, \"payload\": {\"case_id\": cid, \"case_title\": ttl}})\n","            for cid,(sc,ttl) in ranked]\n","\n","def search_cases_MAX_with_candidates(\n","    question: str,\n","    candidate_case_ids: list[int],\n","    k: int = DEFAULTS[\"top_cases_show\"],\n","    m_query: int = DEFAULTS[\"case_m_query\"],\n","    per_subvec_limit: int = DEFAULTS[\"case_per_subvec_limit\"],\n","    hnsw_ef: int = DEFAULTS[\"case_hnsw_ef\"]\n","):\n","    \"\"\"\n","    Optional second-stage case-level re-ranking within candidate cases using MAX fusion.\n","    Useful if you want a hybrid score (page + case).\n","    \"\"\"\n","    if not candidate_case_ids:\n","        return []\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    try:\n","        params = models.SearchParams(hnsw_ef=hnsw_ef)\n","    except Exception:\n","        params = None\n","\n","    qfilter = models.Filter(should=[\n","        models.FieldCondition(key=\"case_id\", match=models.MatchValue(value=int(cid)))\n","        for cid in candidate_case_ids\n","    ])\n","\n","    agg = {}  # case_point_id -> (max_score, payload)\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","    return [type(\"Hit\", (), {\"id\": i, \"score\": sc, \"payload\": pl}) for i,(sc,pl) in ranked]\n","\n","def fuse_cases(page_hits, case_hits, w_page=0.75, w_case=0.25, top_k=DEFAULTS[\"top_cases_show\"]):\n","    \"\"\"\n","    Hybrid fusion: final_score = w_page * max_page_score + w_case * case_level_score.\n","    Keeps page evidence while stabilizing with case-level signal.\n","    \"\"\"\n","    page_best = {}\n","    for h in page_hits:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        ttl = p.get(\"case_title\",\"\")\n","        if cid not in page_best or h.score > page_best[cid][0]:\n","            page_best[cid] = (h.score, ttl)\n","\n","    case_best = {}\n","    for h in case_hits:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        ttl = p.get(\"case_title\",\"\")\n","        if cid not in case_best or h.score > case_best[cid][0]:\n","            case_best[cid] = (h.score, ttl)\n","\n","    all_ids = set(page_best) | set(case_best)\n","    fused = []\n","    for cid in all_ids:\n","        ps = page_best.get(cid, (0.0, \"\"))[0]\n","        cs = case_best.get(cid, (0.0, \"\"))[0]\n","        ttl = (page_best.get(cid) or case_best.get(cid) or (0.0, \"\"))[1]\n","        fused.append((cid, w_page*ps + w_case*cs, ttl))\n","\n","    fused.sort(key=lambda x: x[1], reverse=True)\n","    return [type(\"Hit\", (), {\"id\": cid, \"score\": sc, \"payload\": {\"case_id\": cid, \"case_title\": ttl}})\n","            for cid,sc,ttl in fused[:top_k]]\n"],"metadata":{"id":"U8Jtt-CccJkF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get best evidence pages per case (for OCR/LLM)"],"metadata":{"id":"Ryv7SiPehWVi"}},{"cell_type":"code","source":["def search_pages_in_case(\n","    question: str,\n","    case_id: int,\n","    top_pages: int = 3,\n","    m_query: int = DEFAULTS[\"page_m_query\"],\n","    per_subvec_limit: int = DEFAULTS[\"page_per_subvec_limit\"],\n","    hnsw_ef: int = DEFAULTS[\"page_hnsw_ef\"]\n","):\n","    \"\"\"\n","    Retrieve the best evidence pages within a specific case_id.\n","    Useful to assemble citations and OCR text for the LLM.\n","    \"\"\"\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    try:\n","        params = models.SearchParams(hnsw_ef=hnsw_ef)\n","    except Exception:\n","        params = None\n","\n","    qfilter = models.Filter(must=[\n","        models.FieldCondition(key=\"case_id\", match=models.MatchValue(value=int(case_id)))\n","    ])\n","\n","    agg = {}  # page_point_id -> (max_score, payload)\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_PAGES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:top_pages]\n","\n","    # Normalize payload for OCR convenience\n","    out = []\n","    for pid,(sc,pl) in ranked:\n","        out.append({\n","            \"id\": pid,\n","            \"score\": float(sc),\n","            \"case_id\": int(pl.get(\"case_id\")),\n","            \"case_title\": pl.get(\"case_title\",\"\"),\n","            \"page_number\": pl.get(\"page_number\"),\n","            \"path\": pl.get(\"path\") or (pl.get(\"page_paths\") or [None])[0]\n","        })\n","    return out\n"],"metadata":{"id":"DK0tPRBJcWJz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## OCR & build context text for the LLM"],"metadata":{"id":"wFwnZ2ztha_l"}},{"cell_type":"code","source":["import re\n","from PIL import Image\n","import pytesseract\n","\n","def clean_text(s: str) -> str:\n","    \"\"\"Basic cleanup for OCR output: de-hyphen, collapse whitespace, normalize line breaks.\"\"\"\n","    s = re.sub(r'-\\n', '', s)\n","    s = re.sub(r'[ \\t]+\\n', '\\n', s)\n","    s = re.sub(r'\\n{2,}', '\\n\\n', s)\n","    return s.strip()\n","\n","def ocr_image_page(path: str, lang=\"eng\") -> str:\n","    \"\"\"OCR a page image (PNG/JPG) and return cleaned text.\"\"\"\n","    img = Image.open(path)\n","    txt = pytesseract.image_to_string(img, lang=lang)\n","    return clean_text(txt)\n","\n","def build_context_from_pages(pages: list[dict], max_chars: int = DEFAULTS[\"max_context_chars\"]) -> tuple[str, list[dict]]:\n","    \"\"\"\n","    Build a compact textual CONTEXT for the LLM:\n","    - pages: list of dicts with {case_id, case_title, page_number, path, score}\n","    - returns (context_text, contexts_meta_for_logging)\n","    \"\"\"\n","    ctx_blocks, meta = [], []\n","    total = 0\n","    for p in pages:\n","        text = ocr_image_page(p[\"path\"])\n","        if not text:\n","            continue\n","        header = f\"[Case {p['case_id']} | {p.get('case_title','')} | page {p['page_number']} | score {p['score']:.3f}]\"\n","        block = f\"{header}\\n{text}\"\n","        if total + len(block) > max_chars:\n","            break\n","        ctx_blocks.append(block)\n","        meta.append({\n","            \"case_id\": p[\"case_id\"], \"case_title\": p.get(\"case_title\",\"\"),\n","            \"page_number\": p[\"page_number\"], \"path\": p[\"path\"], \"score\": p[\"score\"],\n","            \"snippet\": text[:300]\n","        })\n","        total += len(block)\n","    return \"\\n\\n\".join(ctx_blocks), meta\n"],"metadata":{"id":"nqy8z4JDcYh9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## End-to-End helper (query â†’ pages â†’ cases â†’ context)"],"metadata":{"id":"oZUmkVHJhivS"}},{"cell_type":"code","source":["def retrieve_e2e(\n","    question: str,\n","    pages_per_case_for_context: int = DEFAULTS[\"pages_per_case_for_context\"],\n","    use_fusion: bool = False,   # False: PAGEâ†’CASE only; True: Fusion (PAGE+CASE)\n","    show_intermediate: bool = True\n","):\n","    # Stage-1: page-level (broad)\n","    page_hits = search_pages_MAX(\n","        question,\n","        k_pages=max(DEFAULTS[\"top_pages_show\"], DEFAULTS[\"candidate_cases\"]),\n","        m_query=DEFAULTS[\"page_m_query\"],\n","        per_subvec_limit=DEFAULTS[\"page_per_subvec_limit\"],\n","        hnsw_ef=DEFAULTS[\"page_hnsw_ef\"]\n","    )\n","    if show_intermediate:\n","        print_page_hits(page_hits, title=\"\\n=== Top pages (evidence) ===\", limit=DEFAULTS[\"top_pages_show\"])\n","\n","    # Collect candidate case_ids from best page scores\n","    candidates = pages_to_case_candidates(page_hits, top_cases=DEFAULTS[\"candidate_cases\"])\n","    if show_intermediate:\n","        print(\"\\nCandidates (first 20):\", candidates[:20])\n","\n","    # Stage-2: case-level re-ranking (optional)\n","    if use_fusion:\n","        # Wide case-level search within candidates, then fuse with page scores\n","        case_hits_wide = search_cases_MAX_with_candidates(\n","            question,\n","            candidate_case_ids=candidates,\n","            k=DEFAULTS[\"candidate_cases\"],\n","            m_query=DEFAULTS[\"case_m_query\"],\n","            per_subvec_limit=DEFAULTS[\"case_per_subvec_limit\"],\n","            hnsw_ef=DEFAULTS[\"case_hnsw_ef\"]\n","        )\n","        final_cases = fuse_cases(page_hits, case_hits_wide, w_page=0.75, w_case=0.25, top_k=DEFAULTS[\"top_cases_show\"])\n","    else:\n","        # Pure PAGEâ†’CASE ranking (recommended for strong page evidence)\n","        final_cases = rank_cases_from_pages(page_hits, top_k=DEFAULTS[\"top_cases_show\"])\n","\n","    print_case_hits(final_cases, title=\"\\n=== Final case hits ===\")\n","\n","    # Fetch best pages per final case (to feed OCR/LLM and show citations)\n","    pages_by_case = {}\n","    for h in final_cases:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        pages = search_pages_in_case(\n","            question, case_id=cid,\n","            top_pages=pages_per_case_for_context,\n","            m_query=DEFAULTS[\"page_m_query\"],\n","            per_subvec_limit=DEFAULTS[\"page_per_subvec_limit\"],\n","            hnsw_ef=DEFAULTS[\"page_hnsw_ef\"]\n","        )\n","        pages_by_case[cid] = pages\n","        print(f\"\\n--- Best pages for case_id={cid} ---\")\n","        for j, pg in enumerate(pages, 1):\n","            print(f\"  p{j} | score={pg['score']:.3f} | {pg['path']}\")\n","\n","    # Build the LLM context from the selected pages (ordered by final cases)\n","    ranked_pages_for_ctx = []\n","    for h in final_cases:\n","        cid = int((h.payload or {}).get(\"case_id\"))\n","        ranked_pages_for_ctx.extend(pages_by_case.get(cid, []))\n","\n","    context_text, contexts_meta = build_context_from_pages(\n","        ranked_pages_for_ctx, max_chars=DEFAULTS[\"max_context_chars\"]\n","    )\n","    print(f\"\\n[context chars] {len(context_text)}\")\n","\n","    return dict(\n","        page_hits=page_hits,\n","        final_cases=final_cases,\n","        pages_by_case=pages_by_case,\n","        context_text=context_text,\n","        contexts_meta=contexts_meta\n","    )\n"],"metadata":{"id":"S-uOV-5Th3i-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Example query (Ebola)"],"metadata":{"id":"iAOqjKKWh5jm"}},{"cell_type":"code","source":["question = (\n","  \"Ebola virus disease: hemorrhagic fever with bleeding and shock; \"\n","  \"nursing isolation, PPE and contact precautions; patient from Sudan.\"\n",")\n","\n","result = retrieve_e2e(\n","    question,\n","    pages_per_case_for_context=DEFAULTS[\"pages_per_case_for_context\"],\n","    use_fusion=False,   # set True to combine PAGE and CASE signals\n","    show_intermediate=True\n",")\n","\n","\n"],"metadata":{"id":"OoSJ2CCcckbs"},"execution_count":null,"outputs":[]}]}