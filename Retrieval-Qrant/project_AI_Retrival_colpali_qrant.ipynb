{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMpROqV8YxmfmhGcyN6y4QM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6d7443300ba2414d955ce2f791fce5d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81cae1ab18b14f8689dc07f8e63d7379","IPY_MODEL_61fce67d65b8430589b4adde5e3cc268","IPY_MODEL_5530c60d8bd2468f86925187e86e1115"],"layout":"IPY_MODEL_d047ef9bf2dd427b9fe3ec122fbd9453"}},"81cae1ab18b14f8689dc07f8e63d7379":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b12bb36581434c1b90ae061833fc6cc5","placeholder":"​","style":"IPY_MODEL_6341d7210468416489973960e56abfe7","value":"config.json: "}},"61fce67d65b8430589b4adde5e3cc268":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b81b856ccc84a4798b91590ffa3a7a1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02b6271f4ac048078482b286ebf83034","value":1}},"5530c60d8bd2468f86925187e86e1115":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c5267ebbc424ed2984a2d7fb83569dd","placeholder":"​","style":"IPY_MODEL_4300c99c24534badb7afc6475b916dd6","value":" 1.05k/? [00:00&lt;00:00, 71.5kB/s]"}},"d047ef9bf2dd427b9fe3ec122fbd9453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b12bb36581434c1b90ae061833fc6cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6341d7210468416489973960e56abfe7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b81b856ccc84a4798b91590ffa3a7a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"02b6271f4ac048078482b286ebf83034":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c5267ebbc424ed2984a2d7fb83569dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4300c99c24534badb7afc6475b916dd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a0e606fd7594d5792e311ccbc10aa62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e21f3121e274594a76bb2ac57b85d9a","IPY_MODEL_6cdf3e226a084df792ba13cfae7fa976","IPY_MODEL_c317a70eb4cf47c591fd28f8a948dbe2"],"layout":"IPY_MODEL_0b39ec2fc8694bc98498fabe406d1d2e"}},"8e21f3121e274594a76bb2ac57b85d9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7447edc535f342c6a8c9f1ab5dc3f11c","placeholder":"​","style":"IPY_MODEL_d1aa137985084df5be7f41db00d76397","value":"model.safetensors.index.json: "}},"6cdf3e226a084df792ba13cfae7fa976":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a47d8a0341441a889b80b64071f9ce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d079bf9e0d1942238870a38e3dd79aa7","value":1}},"c317a70eb4cf47c591fd28f8a948dbe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a7684a4d7804908b51bc31067264a18","placeholder":"​","style":"IPY_MODEL_8875495a418b40e4b21593c9e605d3a0","value":" 65.1k/? [00:00&lt;00:00, 2.46MB/s]"}},"0b39ec2fc8694bc98498fabe406d1d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7447edc535f342c6a8c9f1ab5dc3f11c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1aa137985084df5be7f41db00d76397":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3a47d8a0341441a889b80b64071f9ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d079bf9e0d1942238870a38e3dd79aa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a7684a4d7804908b51bc31067264a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8875495a418b40e4b21593c9e605d3a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90706c40e65b4657afe8d808e0a50023":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aab257b732e34ff4bae7c5102f353948","IPY_MODEL_bf13983335114598aeed2a95398bcd7c","IPY_MODEL_ce93910a2e2e437f89d7b0a664b42357"],"layout":"IPY_MODEL_a84978bfed6c4371bc845dc4cc546be1"}},"aab257b732e34ff4bae7c5102f353948":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fce6297050140409412e39b73986b93","placeholder":"​","style":"IPY_MODEL_42599313a71d4450adc24c1043d20ccb","value":"Fetching 2 files: 100%"}},"bf13983335114598aeed2a95398bcd7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2783c4ab3caa45f9a22545a3352a2ed7","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53581c55bc7949e496f3ca1d8ee7428a","value":2}},"ce93910a2e2e437f89d7b0a664b42357":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29fc5c9e495a41fc8afdee08c49304c1","placeholder":"​","style":"IPY_MODEL_2e86df9deb1c4f16b45f64e48039b9e9","value":" 2/2 [01:21&lt;00:00, 81.37s/it]"}},"a84978bfed6c4371bc845dc4cc546be1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fce6297050140409412e39b73986b93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42599313a71d4450adc24c1043d20ccb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2783c4ab3caa45f9a22545a3352a2ed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53581c55bc7949e496f3ca1d8ee7428a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29fc5c9e495a41fc8afdee08c49304c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e86df9deb1c4f16b45f64e48039b9e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2601cb0b0fc4b64a1deef09d516b8d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85f6f3b64a4c45de8b072334864e0e12","IPY_MODEL_e3d7bd9290d046d2a762cd1abacb992f","IPY_MODEL_333bc609c04e444eb245c45508c0da36"],"layout":"IPY_MODEL_defbc45ffaea43a08798543bdceda748"}},"85f6f3b64a4c45de8b072334864e0e12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad0617a04006448f9e4151749c83e164","placeholder":"​","style":"IPY_MODEL_cebc55d4cacf4885ac2a61e6c0d0bed4","value":"model-00001-of-00002.safetensors: 100%"}},"e3d7bd9290d046d2a762cd1abacb992f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88e92519f0af49b294e72e2703ce271a","max":4986816144,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb249b4697a44fafa551f0b69f6de39b","value":4986816144}},"333bc609c04e444eb245c45508c0da36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3454961e5b6423394e2facfe36991b4","placeholder":"​","style":"IPY_MODEL_8c973d3d38aa4a749d2e42ca71f5c578","value":" 4.99G/4.99G [01:21&lt;00:00, 107MB/s]"}},"defbc45ffaea43a08798543bdceda748":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad0617a04006448f9e4151749c83e164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cebc55d4cacf4885ac2a61e6c0d0bed4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88e92519f0af49b294e72e2703ce271a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb249b4697a44fafa551f0b69f6de39b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3454961e5b6423394e2facfe36991b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c973d3d38aa4a749d2e42ca71f5c578":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f513587cc194575a5d45afbc83f668e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aaf1b8871892441e853cf9d09f19f51e","IPY_MODEL_a0f4381f485849ffb76bcd8171add2ff","IPY_MODEL_dc0a018bfc484c5c8278beb18f41f724"],"layout":"IPY_MODEL_d67039c62ec445d1a6781cabf18ac7be"}},"aaf1b8871892441e853cf9d09f19f51e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a255db06d6a54c6a98f263cad9655314","placeholder":"​","style":"IPY_MODEL_2802641071bc4c7a8a53b12f7f705fd5","value":"model-00002-of-00002.safetensors: 100%"}},"a0f4381f485849ffb76bcd8171add2ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45703b5c073b478cb6ff820bd867d614","max":862495464,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99af1c2493234c5897b4f22d39ecbb87","value":862495464}},"dc0a018bfc484c5c8278beb18f41f724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_526d0add9c184f3db3aebcd8b9270283","placeholder":"​","style":"IPY_MODEL_d1bfcf9e8e8849058cd6bf4d1d481dc0","value":" 862M/862M [00:46&lt;00:00, 32.9MB/s]"}},"d67039c62ec445d1a6781cabf18ac7be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a255db06d6a54c6a98f263cad9655314":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2802641071bc4c7a8a53b12f7f705fd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45703b5c073b478cb6ff820bd867d614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99af1c2493234c5897b4f22d39ecbb87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"526d0add9c184f3db3aebcd8b9270283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1bfcf9e8e8849058cd6bf4d1d481dc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7134f2b858be4ba8b6bd7815c9b2ac35":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3594600984a4932b57fb27c4fa58590","IPY_MODEL_95805283d87140048cfde5c431eee78a","IPY_MODEL_c779385400e84f9d9808545f6e4f5606"],"layout":"IPY_MODEL_e2a0196eda58455e9bf93f7b39ce3fa7"}},"d3594600984a4932b57fb27c4fa58590":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35a17074d81d44bf8e2f8e261eac9630","placeholder":"​","style":"IPY_MODEL_b19168c0e3bf45409b4096c9e6da3e00","value":"Loading checkpoint shards: 100%"}},"95805283d87140048cfde5c431eee78a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e1424455644195834688c23057e995","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb95fa68deea47469e68f4fe01103a99","value":2}},"c779385400e84f9d9808545f6e4f5606":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e996584af1384e8d91ecc66ec472dc96","placeholder":"​","style":"IPY_MODEL_a2beb73328da4301b1c6c641abe9b22a","value":" 2/2 [00:00&lt;00:00,  7.84it/s]"}},"e2a0196eda58455e9bf93f7b39ce3fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35a17074d81d44bf8e2f8e261eac9630":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b19168c0e3bf45409b4096c9e6da3e00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61e1424455644195834688c23057e995":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb95fa68deea47469e68f4fe01103a99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e996584af1384e8d91ecc66ec472dc96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2beb73328da4301b1c6c641abe9b22a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05a590a0c9cd4645ba21a87cbf0530d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8eb47d3ab0d4c6daa36014e58ff3575","IPY_MODEL_45a9dfac329249cdb289a746f618c764","IPY_MODEL_e017db76cedb41ec9350d3c4bb82b0b5"],"layout":"IPY_MODEL_4fe7ea7a53f5491b9f09dcb6391b47d2"}},"f8eb47d3ab0d4c6daa36014e58ff3575":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c8f747548914723bbd7ff3d7bdbffc2","placeholder":"​","style":"IPY_MODEL_9b302060fc5e4a8780fe350ad3256de2","value":"preprocessor_config.json: 100%"}},"45a9dfac329249cdb289a746f618c764":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_470503e361734d219a8b7a2a8eee25b6","max":700,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21476e32c09341718c7d661ff7d89b1d","value":700}},"e017db76cedb41ec9350d3c4bb82b0b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a1a1295091d49b894df1b202edd83d5","placeholder":"​","style":"IPY_MODEL_72a191ebd25b42a1be10325bee3a3955","value":" 700/700 [00:00&lt;00:00, 61.2kB/s]"}},"4fe7ea7a53f5491b9f09dcb6391b47d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c8f747548914723bbd7ff3d7bdbffc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b302060fc5e4a8780fe350ad3256de2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"470503e361734d219a8b7a2a8eee25b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21476e32c09341718c7d661ff7d89b1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a1a1295091d49b894df1b202edd83d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72a191ebd25b42a1be10325bee3a3955":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"339ad5c0a1054df6a13042e20053c0c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7001ed5d00748658db640566a33ab83","IPY_MODEL_5ec5dbdcfc814e90ad7c557b746c71e8","IPY_MODEL_16a8f82803254849a15b6f1c0c5fce9b"],"layout":"IPY_MODEL_3b5f115a924d462aaa1c18d0b8bb7e41"}},"e7001ed5d00748658db640566a33ab83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81c930efa2ef473aaa7f131666b95961","placeholder":"​","style":"IPY_MODEL_900b6e3a89544a109e132dd9ce1e56fb","value":"tokenizer_config.json: "}},"5ec5dbdcfc814e90ad7c557b746c71e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c93d2abec654cfe9aa58d0c667c40fc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9094c341a1b41f0b10d6c6eb7fad6dd","value":1}},"16a8f82803254849a15b6f1c0c5fce9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff6d55cbcd7f4e01b3248182c26f4cc1","placeholder":"​","style":"IPY_MODEL_028062577ca74e54a4d9b498ad21e39e","value":" 243k/? [00:00&lt;00:00, 17.4MB/s]"}},"3b5f115a924d462aaa1c18d0b8bb7e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81c930efa2ef473aaa7f131666b95961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900b6e3a89544a109e132dd9ce1e56fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c93d2abec654cfe9aa58d0c667c40fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a9094c341a1b41f0b10d6c6eb7fad6dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff6d55cbcd7f4e01b3248182c26f4cc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"028062577ca74e54a4d9b498ad21e39e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7ad15faccbd4f6d829d08b07e3824be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb5f7edfcb0642c2bcc72a43ed1aad49","IPY_MODEL_343d38cad1eb4e6bbbbb97b3e4023e77","IPY_MODEL_2c1a994c932b4c50a6f7c8359caf872a"],"layout":"IPY_MODEL_e260d971f07e48b1be977386c4b4fee2"}},"bb5f7edfcb0642c2bcc72a43ed1aad49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a196c0c90c24b79b7c2c43d29117a9f","placeholder":"​","style":"IPY_MODEL_f5e697af273c445992bd78d1de443f06","value":"tokenizer.json: 100%"}},"343d38cad1eb4e6bbbbb97b3e4023e77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d67c3a7910e46d5a1a6a55588a3d891","max":17763459,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9459fa32e05d40589680e74909305126","value":17763459}},"2c1a994c932b4c50a6f7c8359caf872a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df334a271dd44955a65219f57572391b","placeholder":"​","style":"IPY_MODEL_f47923044f5545ef9de898acd5ab6ff9","value":" 17.8M/17.8M [00:00&lt;00:00, 27.3MB/s]"}},"e260d971f07e48b1be977386c4b4fee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a196c0c90c24b79b7c2c43d29117a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5e697af273c445992bd78d1de443f06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d67c3a7910e46d5a1a6a55588a3d891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9459fa32e05d40589680e74909305126":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df334a271dd44955a65219f57572391b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f47923044f5545ef9de898acd5ab6ff9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"398ecdb719a644d698dbaca1adb8f726":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4617cf77c144ad09577cff839db563c","IPY_MODEL_bda27a3a34af485ba787315e5a1a3882","IPY_MODEL_3310640b6ab14fa3839d6a5f33e2879d"],"layout":"IPY_MODEL_e9426b3157df4d789f3d93072ac7cb50"}},"f4617cf77c144ad09577cff839db563c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_239677ffd8ac4167abd2c1c80539b690","placeholder":"​","style":"IPY_MODEL_ee06ce0de3de4456851f305d6e0b854e","value":"special_tokens_map.json: 100%"}},"bda27a3a34af485ba787315e5a1a3882":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31ddeebe78ab4bbfa7ca7aeab23c3bd8","max":733,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53a9543728be4196a64e2021fb192e6a","value":733}},"3310640b6ab14fa3839d6a5f33e2879d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_523dd14271b5444999b46f206aeb5078","placeholder":"​","style":"IPY_MODEL_74af039c7ea7464380b7529470268571","value":" 733/733 [00:00&lt;00:00, 94.6kB/s]"}},"e9426b3157df4d789f3d93072ac7cb50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"239677ffd8ac4167abd2c1c80539b690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee06ce0de3de4456851f305d6e0b854e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31ddeebe78ab4bbfa7ca7aeab23c3bd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53a9543728be4196a64e2021fb192e6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"523dd14271b5444999b46f206aeb5078":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74af039c7ea7464380b7529470268571":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\", force_remount=True)\n","    print(\"[colab] Drive mounted at /content/drive\")\n","except Exception as e:\n","    print(\"[note] Not in Colab or Drive mount failed:\", e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUaT64ZyEU4Q","executionInfo":{"status":"ok","timestamp":1761742031198,"user_tz":-420,"elapsed":23054,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"8cae5f61-206d-4b12-8b23-790c3126785b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[colab] Drive mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WatXcgE4qWFP","executionInfo":{"status":"ok","timestamp":1761732962453,"user_tz":-420,"elapsed":248428,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"16993a5b-6451-47da-a5b9-6e879ca4dcd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m134.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hapt-get -y update && apt-get -y install tesseract-ocr poppler-utils\n"]}],"source":["import sys, subprocess, os\n","def sh(cmd): print(cmd); subprocess.run(cmd, shell=True, check=True)\n","\n","# CUDA 12.1-compatible torch for Colab\n","!python3 -m pip -q install --index-url https://download.pytorch.org/whl/cu121 \"torch==2.5.1\" \"torchaudio==2.5.1\" \"torchvision==0.20.1\"\n","# Core libs: ColPali, transformers, qdrant-client (multi-vector), OCR, PDF\n","!python3 -m pip -q install \"transformers>=4.53.1,<4.54.0\" colpali-engine==0.3.12 \"qdrant-client>=1.7.3,<2\" accelerate sentencepiece pdf2image pytesseract\n","# System deps for OCR/PDF\n","sh('apt-get -y update && apt-get -y install tesseract-ocr poppler-utils')"]},{"cell_type":"code","source":["SOURCE_DIR         = \"/content/drive/MyDrive/Project-AI/PDF-Data\"\n","MODEL_NAME         = \"vidore/colpali-v1.2-hf\"\n","\n","# Outputs\n","PAGES_JSONL        = \"/content/clinical_cases_index.jsonl\"\n","CASES_JSONL        = \"/content/clinical_cases_cases.jsonl\"\n","STRUCT_JSONL       = \"/content/clinical_cases_cases_structured.jsonl\"\n","SFT_EXTRACT_JSONL  = \"/content/clinical_cases_extract_sft.jsonl\"\n","SFT_DX_JSONL       = \"/content/clinical_cases_dx_sft.jsonl\"\n","\n","# Qdrant collections\n","COLLECTION_PAGES   = \"tropical_cases_colpali_pages\"\n","COLLECTION_CASES   = \"tropical_cases_colpali_cases\"\n","VECTOR_SIZE        = 128  # ColPali subvector dim\n","VECTOR_NAME = \"default\"\n","\n","# Toggles\n","INDEX_PAGES        = True\n","INDEX_CASES        = True\n","ENABLE_OCR         = True\n","ENABLE_PDF         = True\n","BATCH              = 2      # embedding batch size\n","MAX_FILES          = None   # set small int to smoke-test\n","\n","# Qdrant remote (REST-only)\n","QDRANT_HOST        = \"165.22.56.15\"\n","QDRANT_PORT        = 6333    # QRPcQDRANT_API_KEY     = os.getenv(\"QDRANT_API_KEY\") or None\n","QDRANT_TIMEOUT     = 1200.0  # large to be safe\n","UPSERT_BATCH       = 12      # points per upsert() call; keep small for reliability\n","UPSERT_MAX_RETRIES = 6"],"metadata":{"id":"GSmh86eYroIl","executionInfo":{"status":"ok","timestamp":1761732962463,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import re, json, glob, hashlib, io, time\n","from typing import List, Dict, Any, Tuple\n","from PIL import Image\n","from tqdm import tqdm\n","import torch\n","from collections import defaultdict\n","from typing import Optional\n","\n","\n","from transformers import ColPaliForRetrieval, ColPaliProcessor\n","from qdrant_client import QdrantClient, models\n","\n","try:\n","    import pytesseract\n","except Exception as e:\n","    print(\"[warn] OCR disabled:\", e); ENABLE_OCR=False\n","\n","try:\n","    from pdf2image import convert_from_path\n","except Exception as e:\n","    print(\"[warn] PDF→image disabled:\", e); ENABLE_PDF=False"],"metadata":{"id":"aw_FberUrwAc","executionInfo":{"status":"ok","timestamp":1761733269576,"user_tz":-420,"elapsed":41,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def load_colpali(device=None):\n","    device = device or (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"[env] device={device}\\n[env] loading ColPali…\")\n","\n","    model = ColPaliForRetrieval.from_pretrained(\n","        MODEL_NAME,\n","        torch_dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32),\n","    ).eval()\n","    model.to(device)\n","\n","    processor = ColPaliProcessor.from_pretrained(MODEL_NAME)\n","    print(\"[env] ColPali loaded.\")\n","    return model, processor, device\n","\n","@torch.no_grad()\n","def embed_images(model, processor, device, pil_images: List[Image.Image]):\n","    batch = processor(images=pil_images).to(device)\n","    emb = model(**batch).embeddings  # [B, N, 128] multivectors\n","    return [e.to(\"cpu\").float().tolist() for e in emb]  # List[List[List[float]]]\n","\n","@torch.no_grad()\n","def embed_queries(model, processor, device, queries: List[str]):\n","    batch = processor(text=queries).to(device)\n","    emb = model(**batch).embeddings\n","    return [e.to(\"cpu\").float().tolist() for e in emb]"],"metadata":{"id":"1xwRwnd42Lm9","executionInfo":{"status":"ok","timestamp":1761732992598,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def connect_qdrant_rest():\n","    url = f\"http://{QDRANT_HOST}:{QDRANT_PORT}\"\n","    client = QdrantClient(\n","        url=url,\n","        api_key=None,\n","        timeout=QDRANT_TIMEOUT,\n","        prefer_grpc=False,  # <- HARD disable gRPC\n","    )\n","    # sanity call\n","    client.get_collections()\n","    print(f\"[qdrant] connected (REST-only): {url}\")\n","    return client\n","\n","def ensure_collection(client: QdrantClient, name: str):\n","    try:\n","        exists = client.collection_exists(name)\n","    except Exception:\n","        # REST fallback path if needed\n","        try:\n","            client.http.collections_api.get_collection(name)\n","            exists = True\n","        except Exception:\n","            exists = False\n","\n","    if not exists:\n","        print(f\"[qdrant] creating collection: {name}\")\n","        client.create_collection(\n","            collection_name=name,\n","            vectors_config={\n","                VECTOR_NAME: models.VectorParams(\n","                    size=VECTOR_SIZE,\n","                    distance=models.Distance.COSINE,\n","                    multivector_config=models.MultiVectorConfig(\n","                        comparator=models.MultiVectorComparator.MAX_SIM\n","                    ),\n","                )\n","            },\n","            on_disk_payload=True,\n","            hnsw_config=models.HnswConfigDiff(m=32, ef_construct=128),\n","            optimizers_config=models.OptimizersConfigDiff(default_segment_number=2),\n","        )\n","    else:\n","        print(f\"[qdrant] collection exists: {name}\")\n","\n","# Deterministic 63-bit IDs (so re-runs are true updates)\n","def stable_point_id(key: str) -> int:\n","    h = hashlib.sha1(key.encode(\"utf-8\")).hexdigest()\n","    return int(h[:15], 16) & ((1<<63)-1)"],"metadata":{"id":"gjDrZi7N2Zep","executionInfo":{"status":"ok","timestamp":1761732992612,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["client = connect_qdrant_rest()\n","model, processor, device = load_colpali()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":635,"referenced_widgets":["6d7443300ba2414d955ce2f791fce5d8","81cae1ab18b14f8689dc07f8e63d7379","61fce67d65b8430589b4adde5e3cc268","5530c60d8bd2468f86925187e86e1115","d047ef9bf2dd427b9fe3ec122fbd9453","b12bb36581434c1b90ae061833fc6cc5","6341d7210468416489973960e56abfe7","4b81b856ccc84a4798b91590ffa3a7a1","02b6271f4ac048078482b286ebf83034","3c5267ebbc424ed2984a2d7fb83569dd","4300c99c24534badb7afc6475b916dd6","3a0e606fd7594d5792e311ccbc10aa62","8e21f3121e274594a76bb2ac57b85d9a","6cdf3e226a084df792ba13cfae7fa976","c317a70eb4cf47c591fd28f8a948dbe2","0b39ec2fc8694bc98498fabe406d1d2e","7447edc535f342c6a8c9f1ab5dc3f11c","d1aa137985084df5be7f41db00d76397","e3a47d8a0341441a889b80b64071f9ce","d079bf9e0d1942238870a38e3dd79aa7","5a7684a4d7804908b51bc31067264a18","8875495a418b40e4b21593c9e605d3a0","90706c40e65b4657afe8d808e0a50023","aab257b732e34ff4bae7c5102f353948","bf13983335114598aeed2a95398bcd7c","ce93910a2e2e437f89d7b0a664b42357","a84978bfed6c4371bc845dc4cc546be1","7fce6297050140409412e39b73986b93","42599313a71d4450adc24c1043d20ccb","2783c4ab3caa45f9a22545a3352a2ed7","53581c55bc7949e496f3ca1d8ee7428a","29fc5c9e495a41fc8afdee08c49304c1","2e86df9deb1c4f16b45f64e48039b9e9","e2601cb0b0fc4b64a1deef09d516b8d3","85f6f3b64a4c45de8b072334864e0e12","e3d7bd9290d046d2a762cd1abacb992f","333bc609c04e444eb245c45508c0da36","defbc45ffaea43a08798543bdceda748","ad0617a04006448f9e4151749c83e164","cebc55d4cacf4885ac2a61e6c0d0bed4","88e92519f0af49b294e72e2703ce271a","fb249b4697a44fafa551f0b69f6de39b","f3454961e5b6423394e2facfe36991b4","8c973d3d38aa4a749d2e42ca71f5c578","2f513587cc194575a5d45afbc83f668e","aaf1b8871892441e853cf9d09f19f51e","a0f4381f485849ffb76bcd8171add2ff","dc0a018bfc484c5c8278beb18f41f724","d67039c62ec445d1a6781cabf18ac7be","a255db06d6a54c6a98f263cad9655314","2802641071bc4c7a8a53b12f7f705fd5","45703b5c073b478cb6ff820bd867d614","99af1c2493234c5897b4f22d39ecbb87","526d0add9c184f3db3aebcd8b9270283","d1bfcf9e8e8849058cd6bf4d1d481dc0","7134f2b858be4ba8b6bd7815c9b2ac35","d3594600984a4932b57fb27c4fa58590","95805283d87140048cfde5c431eee78a","c779385400e84f9d9808545f6e4f5606","e2a0196eda58455e9bf93f7b39ce3fa7","35a17074d81d44bf8e2f8e261eac9630","b19168c0e3bf45409b4096c9e6da3e00","61e1424455644195834688c23057e995","eb95fa68deea47469e68f4fe01103a99","e996584af1384e8d91ecc66ec472dc96","a2beb73328da4301b1c6c641abe9b22a","05a590a0c9cd4645ba21a87cbf0530d7","f8eb47d3ab0d4c6daa36014e58ff3575","45a9dfac329249cdb289a746f618c764","e017db76cedb41ec9350d3c4bb82b0b5","4fe7ea7a53f5491b9f09dcb6391b47d2","1c8f747548914723bbd7ff3d7bdbffc2","9b302060fc5e4a8780fe350ad3256de2","470503e361734d219a8b7a2a8eee25b6","21476e32c09341718c7d661ff7d89b1d","9a1a1295091d49b894df1b202edd83d5","72a191ebd25b42a1be10325bee3a3955","339ad5c0a1054df6a13042e20053c0c7","e7001ed5d00748658db640566a33ab83","5ec5dbdcfc814e90ad7c557b746c71e8","16a8f82803254849a15b6f1c0c5fce9b","3b5f115a924d462aaa1c18d0b8bb7e41","81c930efa2ef473aaa7f131666b95961","900b6e3a89544a109e132dd9ce1e56fb","2c93d2abec654cfe9aa58d0c667c40fc","a9094c341a1b41f0b10d6c6eb7fad6dd","ff6d55cbcd7f4e01b3248182c26f4cc1","028062577ca74e54a4d9b498ad21e39e","f7ad15faccbd4f6d829d08b07e3824be","bb5f7edfcb0642c2bcc72a43ed1aad49","343d38cad1eb4e6bbbbb97b3e4023e77","2c1a994c932b4c50a6f7c8359caf872a","e260d971f07e48b1be977386c4b4fee2","9a196c0c90c24b79b7c2c43d29117a9f","f5e697af273c445992bd78d1de443f06","5d67c3a7910e46d5a1a6a55588a3d891","9459fa32e05d40589680e74909305126","df334a271dd44955a65219f57572391b","f47923044f5545ef9de898acd5ab6ff9","398ecdb719a644d698dbaca1adb8f726","f4617cf77c144ad09577cff839db563c","bda27a3a34af485ba787315e5a1a3882","3310640b6ab14fa3839d6a5f33e2879d","e9426b3157df4d789f3d93072ac7cb50","239677ffd8ac4167abd2c1c80539b690","ee06ce0de3de4456851f305d6e0b854e","31ddeebe78ab4bbfa7ca7aeab23c3bd8","53a9543728be4196a64e2021fb192e6a","523dd14271b5444999b46f206aeb5078","74af039c7ea7464380b7529470268571"]},"id":"rZyJETwH3KLd","executionInfo":{"status":"ok","timestamp":1761733223516,"user_tz":-420,"elapsed":230903,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"73d73292-36d6-48fe-9809-65bddf616d94"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[qdrant] connected (REST-only): http://165.22.56.15:6333\n","[env] device=cuda:0\n","[env] loading ColPali…\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d7443300ba2414d955ce2f791fce5d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0e606fd7594d5792e311ccbc10aa62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90706c40e65b4657afe8d808e0a50023"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2601cb0b0fc4b64a1deef09d516b8d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f513587cc194575a5d45afbc83f668e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7134f2b858be4ba8b6bd7815c9b2ac35"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at vidore/colpali-v1.2-hf were not used when initializing ColPaliForRetrieval: ['vlm.language_model.model.embed_tokens.weight', 'vlm.language_model.model.layers.0.input_layernorm.weight', 'vlm.language_model.model.layers.0.mlp.down_proj.weight', 'vlm.language_model.model.layers.0.mlp.gate_proj.weight', 'vlm.language_model.model.layers.0.mlp.up_proj.weight', 'vlm.language_model.model.layers.0.post_attention_layernorm.weight', 'vlm.language_model.model.layers.0.self_attn.k_proj.weight', 'vlm.language_model.model.layers.0.self_attn.o_proj.weight', 'vlm.language_model.model.layers.0.self_attn.q_proj.weight', 'vlm.language_model.model.layers.0.self_attn.v_proj.weight', 'vlm.language_model.model.layers.1.input_layernorm.weight', 'vlm.language_model.model.layers.1.mlp.down_proj.weight', 'vlm.language_model.model.layers.1.mlp.gate_proj.weight', 'vlm.language_model.model.layers.1.mlp.up_proj.weight', 'vlm.language_model.model.layers.1.post_attention_layernorm.weight', 'vlm.language_model.model.layers.1.self_attn.k_proj.weight', 'vlm.language_model.model.layers.1.self_attn.o_proj.weight', 'vlm.language_model.model.layers.1.self_attn.q_proj.weight', 'vlm.language_model.model.layers.1.self_attn.v_proj.weight', 'vlm.language_model.model.layers.10.input_layernorm.weight', 'vlm.language_model.model.layers.10.mlp.down_proj.weight', 'vlm.language_model.model.layers.10.mlp.gate_proj.weight', 'vlm.language_model.model.layers.10.mlp.up_proj.weight', 'vlm.language_model.model.layers.10.post_attention_layernorm.weight', 'vlm.language_model.model.layers.10.self_attn.k_proj.weight', 'vlm.language_model.model.layers.10.self_attn.o_proj.weight', 'vlm.language_model.model.layers.10.self_attn.q_proj.weight', 'vlm.language_model.model.layers.10.self_attn.v_proj.weight', 'vlm.language_model.model.layers.11.input_layernorm.weight', 'vlm.language_model.model.layers.11.mlp.down_proj.weight', 'vlm.language_model.model.layers.11.mlp.gate_proj.weight', 'vlm.language_model.model.layers.11.mlp.up_proj.weight', 'vlm.language_model.model.layers.11.post_attention_layernorm.weight', 'vlm.language_model.model.layers.11.self_attn.k_proj.weight', 'vlm.language_model.model.layers.11.self_attn.o_proj.weight', 'vlm.language_model.model.layers.11.self_attn.q_proj.weight', 'vlm.language_model.model.layers.11.self_attn.v_proj.weight', 'vlm.language_model.model.layers.12.input_layernorm.weight', 'vlm.language_model.model.layers.12.mlp.down_proj.weight', 'vlm.language_model.model.layers.12.mlp.gate_proj.weight', 'vlm.language_model.model.layers.12.mlp.up_proj.weight', 'vlm.language_model.model.layers.12.post_attention_layernorm.weight', 'vlm.language_model.model.layers.12.self_attn.k_proj.weight', 'vlm.language_model.model.layers.12.self_attn.o_proj.weight', 'vlm.language_model.model.layers.12.self_attn.q_proj.weight', 'vlm.language_model.model.layers.12.self_attn.v_proj.weight', 'vlm.language_model.model.layers.13.input_layernorm.weight', 'vlm.language_model.model.layers.13.mlp.down_proj.weight', 'vlm.language_model.model.layers.13.mlp.gate_proj.weight', 'vlm.language_model.model.layers.13.mlp.up_proj.weight', 'vlm.language_model.model.layers.13.post_attention_layernorm.weight', 'vlm.language_model.model.layers.13.self_attn.k_proj.weight', 'vlm.language_model.model.layers.13.self_attn.o_proj.weight', 'vlm.language_model.model.layers.13.self_attn.q_proj.weight', 'vlm.language_model.model.layers.13.self_attn.v_proj.weight', 'vlm.language_model.model.layers.14.input_layernorm.weight', 'vlm.language_model.model.layers.14.mlp.down_proj.weight', 'vlm.language_model.model.layers.14.mlp.gate_proj.weight', 'vlm.language_model.model.layers.14.mlp.up_proj.weight', 'vlm.language_model.model.layers.14.post_attention_layernorm.weight', 'vlm.language_model.model.layers.14.self_attn.k_proj.weight', 'vlm.language_model.model.layers.14.self_attn.o_proj.weight', 'vlm.language_model.model.layers.14.self_attn.q_proj.weight', 'vlm.language_model.model.layers.14.self_attn.v_proj.weight', 'vlm.language_model.model.layers.15.input_layernorm.weight', 'vlm.language_model.model.layers.15.mlp.down_proj.weight', 'vlm.language_model.model.layers.15.mlp.gate_proj.weight', 'vlm.language_model.model.layers.15.mlp.up_proj.weight', 'vlm.language_model.model.layers.15.post_attention_layernorm.weight', 'vlm.language_model.model.layers.15.self_attn.k_proj.weight', 'vlm.language_model.model.layers.15.self_attn.o_proj.weight', 'vlm.language_model.model.layers.15.self_attn.q_proj.weight', 'vlm.language_model.model.layers.15.self_attn.v_proj.weight', 'vlm.language_model.model.layers.16.input_layernorm.weight', 'vlm.language_model.model.layers.16.mlp.down_proj.weight', 'vlm.language_model.model.layers.16.mlp.gate_proj.weight', 'vlm.language_model.model.layers.16.mlp.up_proj.weight', 'vlm.language_model.model.layers.16.post_attention_layernorm.weight', 'vlm.language_model.model.layers.16.self_attn.k_proj.weight', 'vlm.language_model.model.layers.16.self_attn.o_proj.weight', 'vlm.language_model.model.layers.16.self_attn.q_proj.weight', 'vlm.language_model.model.layers.16.self_attn.v_proj.weight', 'vlm.language_model.model.layers.17.input_layernorm.weight', 'vlm.language_model.model.layers.17.mlp.down_proj.weight', 'vlm.language_model.model.layers.17.mlp.gate_proj.weight', 'vlm.language_model.model.layers.17.mlp.up_proj.weight', 'vlm.language_model.model.layers.17.post_attention_layernorm.weight', 'vlm.language_model.model.layers.17.self_attn.k_proj.weight', 'vlm.language_model.model.layers.17.self_attn.o_proj.weight', 'vlm.language_model.model.layers.17.self_attn.q_proj.weight', 'vlm.language_model.model.layers.17.self_attn.v_proj.weight', 'vlm.language_model.model.layers.2.input_layernorm.weight', 'vlm.language_model.model.layers.2.mlp.down_proj.weight', 'vlm.language_model.model.layers.2.mlp.gate_proj.weight', 'vlm.language_model.model.layers.2.mlp.up_proj.weight', 'vlm.language_model.model.layers.2.post_attention_layernorm.weight', 'vlm.language_model.model.layers.2.self_attn.k_proj.weight', 'vlm.language_model.model.layers.2.self_attn.o_proj.weight', 'vlm.language_model.model.layers.2.self_attn.q_proj.weight', 'vlm.language_model.model.layers.2.self_attn.v_proj.weight', 'vlm.language_model.model.layers.3.input_layernorm.weight', 'vlm.language_model.model.layers.3.mlp.down_proj.weight', 'vlm.language_model.model.layers.3.mlp.gate_proj.weight', 'vlm.language_model.model.layers.3.mlp.up_proj.weight', 'vlm.language_model.model.layers.3.post_attention_layernorm.weight', 'vlm.language_model.model.layers.3.self_attn.k_proj.weight', 'vlm.language_model.model.layers.3.self_attn.o_proj.weight', 'vlm.language_model.model.layers.3.self_attn.q_proj.weight', 'vlm.language_model.model.layers.3.self_attn.v_proj.weight', 'vlm.language_model.model.layers.4.input_layernorm.weight', 'vlm.language_model.model.layers.4.mlp.down_proj.weight', 'vlm.language_model.model.layers.4.mlp.gate_proj.weight', 'vlm.language_model.model.layers.4.mlp.up_proj.weight', 'vlm.language_model.model.layers.4.post_attention_layernorm.weight', 'vlm.language_model.model.layers.4.self_attn.k_proj.weight', 'vlm.language_model.model.layers.4.self_attn.o_proj.weight', 'vlm.language_model.model.layers.4.self_attn.q_proj.weight', 'vlm.language_model.model.layers.4.self_attn.v_proj.weight', 'vlm.language_model.model.layers.5.input_layernorm.weight', 'vlm.language_model.model.layers.5.mlp.down_proj.weight', 'vlm.language_model.model.layers.5.mlp.gate_proj.weight', 'vlm.language_model.model.layers.5.mlp.up_proj.weight', 'vlm.language_model.model.layers.5.post_attention_layernorm.weight', 'vlm.language_model.model.layers.5.self_attn.k_proj.weight', 'vlm.language_model.model.layers.5.self_attn.o_proj.weight', 'vlm.language_model.model.layers.5.self_attn.q_proj.weight', 'vlm.language_model.model.layers.5.self_attn.v_proj.weight', 'vlm.language_model.model.layers.6.input_layernorm.weight', 'vlm.language_model.model.layers.6.mlp.down_proj.weight', 'vlm.language_model.model.layers.6.mlp.gate_proj.weight', 'vlm.language_model.model.layers.6.mlp.up_proj.weight', 'vlm.language_model.model.layers.6.post_attention_layernorm.weight', 'vlm.language_model.model.layers.6.self_attn.k_proj.weight', 'vlm.language_model.model.layers.6.self_attn.o_proj.weight', 'vlm.language_model.model.layers.6.self_attn.q_proj.weight', 'vlm.language_model.model.layers.6.self_attn.v_proj.weight', 'vlm.language_model.model.layers.7.input_layernorm.weight', 'vlm.language_model.model.layers.7.mlp.down_proj.weight', 'vlm.language_model.model.layers.7.mlp.gate_proj.weight', 'vlm.language_model.model.layers.7.mlp.up_proj.weight', 'vlm.language_model.model.layers.7.post_attention_layernorm.weight', 'vlm.language_model.model.layers.7.self_attn.k_proj.weight', 'vlm.language_model.model.layers.7.self_attn.o_proj.weight', 'vlm.language_model.model.layers.7.self_attn.q_proj.weight', 'vlm.language_model.model.layers.7.self_attn.v_proj.weight', 'vlm.language_model.model.layers.8.input_layernorm.weight', 'vlm.language_model.model.layers.8.mlp.down_proj.weight', 'vlm.language_model.model.layers.8.mlp.gate_proj.weight', 'vlm.language_model.model.layers.8.mlp.up_proj.weight', 'vlm.language_model.model.layers.8.post_attention_layernorm.weight', 'vlm.language_model.model.layers.8.self_attn.k_proj.weight', 'vlm.language_model.model.layers.8.self_attn.o_proj.weight', 'vlm.language_model.model.layers.8.self_attn.q_proj.weight', 'vlm.language_model.model.layers.8.self_attn.v_proj.weight', 'vlm.language_model.model.layers.9.input_layernorm.weight', 'vlm.language_model.model.layers.9.mlp.down_proj.weight', 'vlm.language_model.model.layers.9.mlp.gate_proj.weight', 'vlm.language_model.model.layers.9.mlp.up_proj.weight', 'vlm.language_model.model.layers.9.post_attention_layernorm.weight', 'vlm.language_model.model.layers.9.self_attn.k_proj.weight', 'vlm.language_model.model.layers.9.self_attn.o_proj.weight', 'vlm.language_model.model.layers.9.self_attn.q_proj.weight', 'vlm.language_model.model.layers.9.self_attn.v_proj.weight', 'vlm.language_model.model.norm.weight', 'vlm.multi_modal_projector.linear.bias', 'vlm.multi_modal_projector.linear.weight', 'vlm.vision_tower.vision_model.embeddings.patch_embedding.bias', 'vlm.vision_tower.vision_model.embeddings.patch_embedding.weight', 'vlm.vision_tower.vision_model.embeddings.position_embedding.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vlm.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vlm.vision_tower.vision_model.post_layernorm.bias', 'vlm.vision_tower.vision_model.post_layernorm.weight']\n","- This IS expected if you are initializing ColPaliForRetrieval from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ColPaliForRetrieval from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ColPaliForRetrieval were not initialized from the model checkpoint at vidore/colpali-v1.2-hf and are newly initialized: ['vlm.lm_head.weight', 'vlm.model.language_model.embed_tokens.weight', 'vlm.model.language_model.layers.0.input_layernorm.weight', 'vlm.model.language_model.layers.0.mlp.down_proj.weight', 'vlm.model.language_model.layers.0.mlp.gate_proj.weight', 'vlm.model.language_model.layers.0.mlp.up_proj.weight', 'vlm.model.language_model.layers.0.post_attention_layernorm.weight', 'vlm.model.language_model.layers.0.self_attn.k_proj.weight', 'vlm.model.language_model.layers.0.self_attn.o_proj.weight', 'vlm.model.language_model.layers.0.self_attn.q_proj.weight', 'vlm.model.language_model.layers.0.self_attn.v_proj.weight', 'vlm.model.language_model.layers.1.input_layernorm.weight', 'vlm.model.language_model.layers.1.mlp.down_proj.weight', 'vlm.model.language_model.layers.1.mlp.gate_proj.weight', 'vlm.model.language_model.layers.1.mlp.up_proj.weight', 'vlm.model.language_model.layers.1.post_attention_layernorm.weight', 'vlm.model.language_model.layers.1.self_attn.k_proj.weight', 'vlm.model.language_model.layers.1.self_attn.o_proj.weight', 'vlm.model.language_model.layers.1.self_attn.q_proj.weight', 'vlm.model.language_model.layers.1.self_attn.v_proj.weight', 'vlm.model.language_model.layers.10.input_layernorm.weight', 'vlm.model.language_model.layers.10.mlp.down_proj.weight', 'vlm.model.language_model.layers.10.mlp.gate_proj.weight', 'vlm.model.language_model.layers.10.mlp.up_proj.weight', 'vlm.model.language_model.layers.10.post_attention_layernorm.weight', 'vlm.model.language_model.layers.10.self_attn.k_proj.weight', 'vlm.model.language_model.layers.10.self_attn.o_proj.weight', 'vlm.model.language_model.layers.10.self_attn.q_proj.weight', 'vlm.model.language_model.layers.10.self_attn.v_proj.weight', 'vlm.model.language_model.layers.11.input_layernorm.weight', 'vlm.model.language_model.layers.11.mlp.down_proj.weight', 'vlm.model.language_model.layers.11.mlp.gate_proj.weight', 'vlm.model.language_model.layers.11.mlp.up_proj.weight', 'vlm.model.language_model.layers.11.post_attention_layernorm.weight', 'vlm.model.language_model.layers.11.self_attn.k_proj.weight', 'vlm.model.language_model.layers.11.self_attn.o_proj.weight', 'vlm.model.language_model.layers.11.self_attn.q_proj.weight', 'vlm.model.language_model.layers.11.self_attn.v_proj.weight', 'vlm.model.language_model.layers.12.input_layernorm.weight', 'vlm.model.language_model.layers.12.mlp.down_proj.weight', 'vlm.model.language_model.layers.12.mlp.gate_proj.weight', 'vlm.model.language_model.layers.12.mlp.up_proj.weight', 'vlm.model.language_model.layers.12.post_attention_layernorm.weight', 'vlm.model.language_model.layers.12.self_attn.k_proj.weight', 'vlm.model.language_model.layers.12.self_attn.o_proj.weight', 'vlm.model.language_model.layers.12.self_attn.q_proj.weight', 'vlm.model.language_model.layers.12.self_attn.v_proj.weight', 'vlm.model.language_model.layers.13.input_layernorm.weight', 'vlm.model.language_model.layers.13.mlp.down_proj.weight', 'vlm.model.language_model.layers.13.mlp.gate_proj.weight', 'vlm.model.language_model.layers.13.mlp.up_proj.weight', 'vlm.model.language_model.layers.13.post_attention_layernorm.weight', 'vlm.model.language_model.layers.13.self_attn.k_proj.weight', 'vlm.model.language_model.layers.13.self_attn.o_proj.weight', 'vlm.model.language_model.layers.13.self_attn.q_proj.weight', 'vlm.model.language_model.layers.13.self_attn.v_proj.weight', 'vlm.model.language_model.layers.14.input_layernorm.weight', 'vlm.model.language_model.layers.14.mlp.down_proj.weight', 'vlm.model.language_model.layers.14.mlp.gate_proj.weight', 'vlm.model.language_model.layers.14.mlp.up_proj.weight', 'vlm.model.language_model.layers.14.post_attention_layernorm.weight', 'vlm.model.language_model.layers.14.self_attn.k_proj.weight', 'vlm.model.language_model.layers.14.self_attn.o_proj.weight', 'vlm.model.language_model.layers.14.self_attn.q_proj.weight', 'vlm.model.language_model.layers.14.self_attn.v_proj.weight', 'vlm.model.language_model.layers.15.input_layernorm.weight', 'vlm.model.language_model.layers.15.mlp.down_proj.weight', 'vlm.model.language_model.layers.15.mlp.gate_proj.weight', 'vlm.model.language_model.layers.15.mlp.up_proj.weight', 'vlm.model.language_model.layers.15.post_attention_layernorm.weight', 'vlm.model.language_model.layers.15.self_attn.k_proj.weight', 'vlm.model.language_model.layers.15.self_attn.o_proj.weight', 'vlm.model.language_model.layers.15.self_attn.q_proj.weight', 'vlm.model.language_model.layers.15.self_attn.v_proj.weight', 'vlm.model.language_model.layers.16.input_layernorm.weight', 'vlm.model.language_model.layers.16.mlp.down_proj.weight', 'vlm.model.language_model.layers.16.mlp.gate_proj.weight', 'vlm.model.language_model.layers.16.mlp.up_proj.weight', 'vlm.model.language_model.layers.16.post_attention_layernorm.weight', 'vlm.model.language_model.layers.16.self_attn.k_proj.weight', 'vlm.model.language_model.layers.16.self_attn.o_proj.weight', 'vlm.model.language_model.layers.16.self_attn.q_proj.weight', 'vlm.model.language_model.layers.16.self_attn.v_proj.weight', 'vlm.model.language_model.layers.17.input_layernorm.weight', 'vlm.model.language_model.layers.17.mlp.down_proj.weight', 'vlm.model.language_model.layers.17.mlp.gate_proj.weight', 'vlm.model.language_model.layers.17.mlp.up_proj.weight', 'vlm.model.language_model.layers.17.post_attention_layernorm.weight', 'vlm.model.language_model.layers.17.self_attn.k_proj.weight', 'vlm.model.language_model.layers.17.self_attn.o_proj.weight', 'vlm.model.language_model.layers.17.self_attn.q_proj.weight', 'vlm.model.language_model.layers.17.self_attn.v_proj.weight', 'vlm.model.language_model.layers.2.input_layernorm.weight', 'vlm.model.language_model.layers.2.mlp.down_proj.weight', 'vlm.model.language_model.layers.2.mlp.gate_proj.weight', 'vlm.model.language_model.layers.2.mlp.up_proj.weight', 'vlm.model.language_model.layers.2.post_attention_layernorm.weight', 'vlm.model.language_model.layers.2.self_attn.k_proj.weight', 'vlm.model.language_model.layers.2.self_attn.o_proj.weight', 'vlm.model.language_model.layers.2.self_attn.q_proj.weight', 'vlm.model.language_model.layers.2.self_attn.v_proj.weight', 'vlm.model.language_model.layers.3.input_layernorm.weight', 'vlm.model.language_model.layers.3.mlp.down_proj.weight', 'vlm.model.language_model.layers.3.mlp.gate_proj.weight', 'vlm.model.language_model.layers.3.mlp.up_proj.weight', 'vlm.model.language_model.layers.3.post_attention_layernorm.weight', 'vlm.model.language_model.layers.3.self_attn.k_proj.weight', 'vlm.model.language_model.layers.3.self_attn.o_proj.weight', 'vlm.model.language_model.layers.3.self_attn.q_proj.weight', 'vlm.model.language_model.layers.3.self_attn.v_proj.weight', 'vlm.model.language_model.layers.4.input_layernorm.weight', 'vlm.model.language_model.layers.4.mlp.down_proj.weight', 'vlm.model.language_model.layers.4.mlp.gate_proj.weight', 'vlm.model.language_model.layers.4.mlp.up_proj.weight', 'vlm.model.language_model.layers.4.post_attention_layernorm.weight', 'vlm.model.language_model.layers.4.self_attn.k_proj.weight', 'vlm.model.language_model.layers.4.self_attn.o_proj.weight', 'vlm.model.language_model.layers.4.self_attn.q_proj.weight', 'vlm.model.language_model.layers.4.self_attn.v_proj.weight', 'vlm.model.language_model.layers.5.input_layernorm.weight', 'vlm.model.language_model.layers.5.mlp.down_proj.weight', 'vlm.model.language_model.layers.5.mlp.gate_proj.weight', 'vlm.model.language_model.layers.5.mlp.up_proj.weight', 'vlm.model.language_model.layers.5.post_attention_layernorm.weight', 'vlm.model.language_model.layers.5.self_attn.k_proj.weight', 'vlm.model.language_model.layers.5.self_attn.o_proj.weight', 'vlm.model.language_model.layers.5.self_attn.q_proj.weight', 'vlm.model.language_model.layers.5.self_attn.v_proj.weight', 'vlm.model.language_model.layers.6.input_layernorm.weight', 'vlm.model.language_model.layers.6.mlp.down_proj.weight', 'vlm.model.language_model.layers.6.mlp.gate_proj.weight', 'vlm.model.language_model.layers.6.mlp.up_proj.weight', 'vlm.model.language_model.layers.6.post_attention_layernorm.weight', 'vlm.model.language_model.layers.6.self_attn.k_proj.weight', 'vlm.model.language_model.layers.6.self_attn.o_proj.weight', 'vlm.model.language_model.layers.6.self_attn.q_proj.weight', 'vlm.model.language_model.layers.6.self_attn.v_proj.weight', 'vlm.model.language_model.layers.7.input_layernorm.weight', 'vlm.model.language_model.layers.7.mlp.down_proj.weight', 'vlm.model.language_model.layers.7.mlp.gate_proj.weight', 'vlm.model.language_model.layers.7.mlp.up_proj.weight', 'vlm.model.language_model.layers.7.post_attention_layernorm.weight', 'vlm.model.language_model.layers.7.self_attn.k_proj.weight', 'vlm.model.language_model.layers.7.self_attn.o_proj.weight', 'vlm.model.language_model.layers.7.self_attn.q_proj.weight', 'vlm.model.language_model.layers.7.self_attn.v_proj.weight', 'vlm.model.language_model.layers.8.input_layernorm.weight', 'vlm.model.language_model.layers.8.mlp.down_proj.weight', 'vlm.model.language_model.layers.8.mlp.gate_proj.weight', 'vlm.model.language_model.layers.8.mlp.up_proj.weight', 'vlm.model.language_model.layers.8.post_attention_layernorm.weight', 'vlm.model.language_model.layers.8.self_attn.k_proj.weight', 'vlm.model.language_model.layers.8.self_attn.o_proj.weight', 'vlm.model.language_model.layers.8.self_attn.q_proj.weight', 'vlm.model.language_model.layers.8.self_attn.v_proj.weight', 'vlm.model.language_model.layers.9.input_layernorm.weight', 'vlm.model.language_model.layers.9.mlp.down_proj.weight', 'vlm.model.language_model.layers.9.mlp.gate_proj.weight', 'vlm.model.language_model.layers.9.mlp.up_proj.weight', 'vlm.model.language_model.layers.9.post_attention_layernorm.weight', 'vlm.model.language_model.layers.9.self_attn.k_proj.weight', 'vlm.model.language_model.layers.9.self_attn.o_proj.weight', 'vlm.model.language_model.layers.9.self_attn.q_proj.weight', 'vlm.model.language_model.layers.9.self_attn.v_proj.weight', 'vlm.model.language_model.norm.weight', 'vlm.model.multi_modal_projector.linear.bias', 'vlm.model.multi_modal_projector.linear.weight', 'vlm.model.vision_tower.vision_model.embeddings.patch_embedding.bias', 'vlm.model.vision_tower.vision_model.embeddings.patch_embedding.weight', 'vlm.model.vision_tower.vision_model.embeddings.position_embedding.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vlm.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vlm.model.vision_tower.vision_model.post_layernorm.bias', 'vlm.model.vision_tower.vision_model.post_layernorm.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05a590a0c9cd4645ba21a87cbf0530d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"339ad5c0a1054df6a13042e20053c0c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7ad15faccbd4f6d829d08b07e3824be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/733 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"398ecdb719a644d698dbaca1adb8f726"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[env] ColPali loaded.\n"]}]},{"cell_type":"markdown","source":["# Retrival with cases-level"],"metadata":{"id":"0hiR7kmQZfgH"}},{"cell_type":"code","source":["info = client.get_collection(COLLECTION_CASES)\n","print(info)  # xem phần vector params / tên\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QitGoiL59G_5","executionInfo":{"status":"ok","timestamp":1761733223876,"user_tz":-420,"elapsed":350,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"6897422e-c5e1-4a69-9a9a-cd799b76b789"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=93 points_count=93 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=128, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=MultiVectorConfig(comparator=<MultiVectorComparator.MAX_SIM: 'max_sim'>)), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=32, ef_construct=128, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=2, max_segment_size=None, memmap_threshold=None, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)) payload_schema={}\n"]}]},{"cell_type":"markdown","source":["###"],"metadata":{"id":"bpDlIrAWarPo"}},{"cell_type":"code","source":["def encode_query_colpali(q: str):\n","\n","    subvecs = embed_queries(model, processor, device, [q])[0]\n","\n","    return [ (sv.tolist() if hasattr(sv, \"tolist\") else list(sv)) for sv in subvecs ]\n","\n","\n","\n","def search_cases_MAX(question: str, k: int = 5, filter_modality: Optional[str] = None):\n","    subvecs = encode_query_colpali(question)\n","\n","    qfilter = None\n","    if filter_modality:\n","        qfilter = models.Filter(must=[\n","            models.FieldCondition(key=\"modality\", match=models.MatchValue(value=filter_modality))\n","        ])\n","\n","    agg = {}\n","\n","    for v in subvecs:\n","\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=k * 4,\n","            with_payload=True,\n","            query_filter=qfilter\n","        )\n","        for h in hits:\n","            pid = h.id\n","            sc  = h.score\n","            pl  = h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","\n","    class Hit:\n","        def __init__(self, _id, score, payload):\n","            self.id = _id; self.score = score; self.payload = payload\n","    return [Hit(_id=i, score=sc, payload=pl) for i,(sc,pl) in ranked]\n","\n","def pretty_print_case_hits(hits):\n","    print()\n","    for i, hit in enumerate(hits, 1):\n","        p = hit.payload or {}\n","        title = p.get(\"case_title\", \"N/A\")\n","        cid   = p.get(\"case_id\", \"N/A\")\n","        n_pg  = p.get(\"n_pages\", \"N/A\")\n","        paths = p.get(\"page_paths\", []) or []\n","        print(f\"Rank {i:>2} | Score: {hit.score:.3f}\")\n","        print(f\"  Case ID    : {cid}\")\n","        print(f\"  Case Title : {title}\")\n","        print(f\"  #Pages     : {n_pg}\")\n","        if paths: print(f\"  First page : {paths[0]}\")\n","        print(\"-\"*88)\n","\n","\n","question = \"What are the symptoms and nursing precautions for Ebola virus infection?\"\n","hits = search_cases_MAX(question, k=5, filter_modality=\"case_multivector\")\n","print(f\"🔎 Query: {question}\")\n","pretty_print_case_hits(hits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nu11PhC7-XjX","executionInfo":{"status":"ok","timestamp":1761733289559,"user_tz":-420,"elapsed":11976,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"2fa510fa-8d8c-4eb2-84a7-c20ce98ad90c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1703315311.py:22: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  hits = client.search(\n"]},{"output_type":"stream","name":"stdout","text":["🔎 Query: What are the symptoms and nursing precautions for Ebola virus infection?\n","\n","Rank  1 | Score: 0.378\n","  Case ID    : 5\n","  Case Title : 5 A 4 Year Old Boy from Laos With a Lesion o 2022 Clinical Cases in Tropic\n","  #Pages     : 2\n","  First page : /content/drive/MyDrive/Project-AI/PDF-Data/5---A-4-Year-Old-Boy-from-Laos-With-a-Lesion-o_2022_Clinical-Cases-in-Tropic_page_1.png\n","----------------------------------------------------------------------------------------\n","Rank  2 | Score: 0.374\n","  Case ID    : 82\n","  Case Title : 82 A 31 Year Old Man from Guatemala With Acute 2022 Clinical Cases in Tro\n","  #Pages     : 3\n","  First page : /content/drive/MyDrive/Project-AI/PDF-Data/82---A-31-Year-Old-Man-from-Guatemala-With-Acute-_2022_Clinical-Cases-in-Tro_page_1.png\n","----------------------------------------------------------------------------------------\n","Rank  3 | Score: 0.372\n","  Case ID    : 19\n","  Case Title : 19 A 40 Year Old Man from Togo With Subcutaneou 2022 Clinical Cases in Tro\n","  #Pages     : 3\n","  First page : /content/drive/MyDrive/Project-AI/PDF-Data/19---A-40-Year-Old-Man-from-Togo-With-Subcutaneou_2022_Clinical-Cases-in-Tro_page_1.png\n","----------------------------------------------------------------------------------------\n","Rank  4 | Score: 0.366\n","  Case ID    : 33\n","  Case Title : 33 A 53 Year Old Man from Malawi With a C 2022 Clinical Cases in Tropical\n","  #Pages     : 3\n","  First page : /content/drive/MyDrive/Project-AI/PDF-Data/33---A-53-Year-Old-Man-from-Malawi-With-a-C_2022_Clinical-Cases-in-Tropical-_page_1.png\n","----------------------------------------------------------------------------------------\n","Rank  5 | Score: 0.363\n","  Case ID    : 17\n","  Case Title : 17 A 34 Year Old Man from Thailand With Feve 2022 Clinical Cases in Tropic\n","  #Pages     : 3\n","  First page : /content/drive/MyDrive/Project-AI/PDF-Data/17---A-34-Year-Old-Man-from-Thailand-With-Feve_2022_Clinical-Cases-in-Tropic_page_1.png\n","----------------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["\n","import re\n","\n","needles = [r\"ebola\", r\"hemorrh\", r\"haemorrh\", r\"sudan\"]\n","rx = re.compile(\"|\".join(needles), flags=re.I)\n","\n","titles = []\n","cursor = None\n","while True:\n","    recs, cursor = client.scroll(\n","        collection_name=COLLECTION_CASES,\n","        with_payload=True,\n","        limit=200,\n","        offset=cursor\n","    )\n","    if not recs:\n","        break\n","    for r in recs:\n","        title = (r.payload or {}).get(\"case_title\",\"\")\n","        if rx.search(title):\n","            titles.append(title)\n","    if cursor is None:\n","        break\n","\n","print(f\"Found {len(titles)} titles matching {needles}:\")\n","for t in titles[:20]:\n","    print(\"-\", t)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9u-cnuNTbNb","executionInfo":{"status":"ok","timestamp":1761733297615,"user_tz":-420,"elapsed":345,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"0f7a151f-f949-46f2-c459-0d0ff8257217"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2 titles matching ['ebola', 'hemorrh', 'haemorrh', 'sudan']:\n","- 44 A 7 Year Old Girl from South Sudan With 2022 Clinical Cases in Tropica\n","- 1 A 20 Year Old Woman from Sudan With Fever 2022 Clinical Cases in Tropi\n"]}]},{"cell_type":"code","source":["\n","records, next_offset = client.scroll(\n","    collection_name=\"tropical_cases_colpali_cases\",\n","    with_payload=True,\n","    with_vectors=True,\n","    limit=1\n",")\n","\n","assert records, \"There are no points in the collection\"\n","\n","point = records[0]\n","\n","\n","vec_field = getattr(point, \"vector\", None)\n","if vec_field is None:\n","    vec_field = getattr(point, \"vectors\", None)\n","\n","print(\"Point type:\", type(point))\n","print(\"Vector field type:\", type(vec_field))\n","\n","\n","if isinstance(vec_field, list):\n","    if vec_field and isinstance(vec_field[0], list):\n","        print(f\"✅ Unnamed MULTI-VECTOR | num_subvectors={len(vec_field)} | dim={len(vec_field[0])}\")\n","    else:\n","        print(f\"✅ SINGLE vector | dim={len(vec_field)}\")\n","elif isinstance(vec_field, dict):\n","    print(\"✅ Named vectors map:\")\n","    for name, v in vec_field.items():\n","        if isinstance(v, list) and v and isinstance(v[0], list):\n","            print(f\"  - {name}: MULTI-VECTOR | num_subvectors={len(v)} | dim={len(v[0])}\")\n","        else:\n","            print(f\"  - {name}: SINGLE vector | dim={len(v)}\")\n","else:\n","    print(\"Vector structure is unclear; print it to inspec\")\n","    print(vec_field)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mn1xn98r_lUl","executionInfo":{"status":"ok","timestamp":1761733302071,"user_tz":-420,"elapsed":1788,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"b72d5662-ab8c-4b34-d511-147ef8c4f04e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Point type: <class 'qdrant_client.http.models.models.Record'>\n","Vector field type: <class 'list'>\n","✅ Unnamed MULTI-VECTOR | num_subvectors=3090 | dim=128\n"]}]},{"cell_type":"code","source":["def encode_query_topk(q: str, top_m: int = 16):\n","    subvecs = embed_queries(model, processor, device, [q])[0]\n","\n","    return subvecs[:top_m]\n","\n","def search_cases_MAX(question: str, k=5, filter_modality=None, m_query=16, per_subvec_limit=20):\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","\n","    qfilter = None\n","    if filter_modality:\n","        qfilter = models.Filter(must=[models.FieldCondition(\n","            key=\"modality\", match=models.MatchValue(value=filter_modality)\n","        )])\n","\n","    agg = {}\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter\n","        )\n","        for h in hits:\n","            pid, sc = h.id, h.score\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, h.payload)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","    return [type(\"Hit\", (), {\"id\": i, \"score\": sc, \"payload\": pl}) for i,(sc,pl) in ranked]\n"],"metadata":{"id":"EtjhHBS-AM6t","executionInfo":{"status":"ok","timestamp":1761733305564,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["question = \"What are the symptoms and nursing precautions for Ebola virus infection?\"\n","hits = search_cases_MAX(question, k=5, filter_modality=\"case_multivector\")\n","for i, h in enumerate(hits, 1):\n","    p = h.payload or {}\n","    print(f\"Rank {i} | score={h.score:.3f}\")\n","    print(\"  Case ID   :\", p.get(\"case_id\"))\n","    print(\"  Title     :\", p.get(\"case_title\"))\n","    print(\"  #Pages    :\", p.get(\"n_pages\"))\n","    paths = p.get(\"page_paths\") or []\n","    if paths: print(\"  FirstPage :\", paths[0])\n","    print(\"-\"*80)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvQVMSVWAmdE","executionInfo":{"status":"ok","timestamp":1761733318041,"user_tz":-420,"elapsed":6281,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"f8f6e9de-0b7c-408a-ebf0-d1c1c759c6cc"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1049930020.py:17: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  hits = client.search(\n"]},{"output_type":"stream","name":"stdout","text":["Rank 1 | score=0.378\n","  Case ID   : 5\n","  Title     : 5 A 4 Year Old Boy from Laos With a Lesion o 2022 Clinical Cases in Tropic\n","  #Pages    : 2\n","  FirstPage : /content/drive/MyDrive/Project-AI/PDF-Data/5---A-4-Year-Old-Boy-from-Laos-With-a-Lesion-o_2022_Clinical-Cases-in-Tropic_page_1.png\n","--------------------------------------------------------------------------------\n","Rank 2 | score=0.374\n","  Case ID   : 82\n","  Title     : 82 A 31 Year Old Man from Guatemala With Acute 2022 Clinical Cases in Tro\n","  #Pages    : 3\n","  FirstPage : /content/drive/MyDrive/Project-AI/PDF-Data/82---A-31-Year-Old-Man-from-Guatemala-With-Acute-_2022_Clinical-Cases-in-Tro_page_1.png\n","--------------------------------------------------------------------------------\n","Rank 3 | score=0.372\n","  Case ID   : 19\n","  Title     : 19 A 40 Year Old Man from Togo With Subcutaneou 2022 Clinical Cases in Tro\n","  #Pages    : 3\n","  FirstPage : /content/drive/MyDrive/Project-AI/PDF-Data/19---A-40-Year-Old-Man-from-Togo-With-Subcutaneou_2022_Clinical-Cases-in-Tro_page_1.png\n","--------------------------------------------------------------------------------\n","Rank 4 | score=0.366\n","  Case ID   : 33\n","  Title     : 33 A 53 Year Old Man from Malawi With a C 2022 Clinical Cases in Tropical\n","  #Pages    : 3\n","  FirstPage : /content/drive/MyDrive/Project-AI/PDF-Data/33---A-53-Year-Old-Man-from-Malawi-With-a-C_2022_Clinical-Cases-in-Tropical-_page_1.png\n","--------------------------------------------------------------------------------\n","Rank 5 | score=0.360\n","  Case ID   : 93\n","  Title     : 93 A 35 Year Old Male Logger from Peru With Fe 2022 Clinical Cases in Trop\n","  #Pages    : 3\n","  FirstPage : /content/drive/MyDrive/Project-AI/PDF-Data/93---A-35-Year-Old-Male-Logger-from-Peru-With-Fe_2022_Clinical-Cases-in-Trop_page_1.png\n","--------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","from IPython.display import display\n","\n","def show_first_pages(hits, top=5):\n","    for h in hits[:top]:\n","        p = h.payload or {}\n","        paths = p.get(\"page_paths\") or []\n","        if not paths:\n","            continue\n","        try:\n","            print(f\"[Case {p.get('case_id')}] {p.get('case_title')}\")\n","            display(Image.open(paths[0]))\n","        except Exception as e:\n","            print(\"Cannot open:\", paths[0], \"->\", e)\n","\n","show_first_pages(hits, top=3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wo3UiltjM6SfdspL68SFQTNCB6grs0cQ"},"id":"NE0ySjsCEK21","executionInfo":{"status":"ok","timestamp":1761733329228,"user_tz":-420,"elapsed":8408,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"bf9b99e6-278d-41d7-9f92-2b37d272b8c2"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["\n","candidates = [1, 44]\n","\n","def search_cases_MAX_restrict(question: str, candidate_case_ids, k=5, m_query=16, per_subvec_limit=40, hnsw_ef=256):\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    params = models.SearchParams(hnsw_ef=hnsw_ef)\n","\n","    qfilter = models.Filter(should=[\n","        models.FieldCondition(key=\"case_id\", match=models.MatchValue(value=int(cid)))\n","        for cid in candidate_case_ids\n","    ])\n","\n","    agg = {}\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","    return [type(\"Hit\", (), {\"id\": i, \"score\": sc, \"payload\": pl}) for i,(sc,pl) in ranked]\n","\n","question = \"Ebola viral hemorrhagic fever with bleeding and shock; nursing isolation and PPE precautions; patient from Sudan.\"\n","hits = search_cases_MAX_restrict(question, candidates, k=5, m_query=12, per_subvec_limit=50, hnsw_ef=256)\n","for i, h in enumerate(hits, 1):\n","    p = h.payload or {}\n","    print(f\"Rank {i} | score={h.score:.3f} | case_id={p.get('case_id')} | {p.get('case_title')}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fY-O3xw9FWpO","executionInfo":{"status":"ok","timestamp":1761733344059,"user_tz":-420,"elapsed":4779,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"8703e797-7d48-4780-b93c-a08749674453"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3072108952.py:14: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  hits = client.search(\n"]},{"output_type":"stream","name":"stdout","text":["Rank 1 | score=0.307 | case_id=1 | 1 A 20 Year Old Woman from Sudan With Fever 2022 Clinical Cases in Tropi\n","Rank 2 | score=0.258 | case_id=44 | 44 A 7 Year Old Girl from South Sudan With 2022 Clinical Cases in Tropica\n"]}]},{"cell_type":"markdown","source":["# Retrival with page-level and then combine with case level for getting case"],"metadata":{"id":"9UHbvOXzbJm1"}},{"cell_type":"markdown","source":["## config"],"metadata":{"id":"0tCbFEH7geYV"}},{"cell_type":"code","source":["\n","\n","# Suggested default parameters (tune as needed)\n","DEFAULTS = dict(\n","    page_m_query=12,               # #sub-vectors from ColPali for page-level\n","    page_per_subvec_limit=120,     # breadth per sub-vector at page-level\n","    page_hnsw_ef=512,              # higher → better recall (slower)\n","    case_m_query=12,               # #sub-vectors from ColPali for case-level\n","    case_per_subvec_limit=80,      # breadth per sub-vector at case-level\n","    case_hnsw_ef=512,              # higher → better recall (slower)\n","    candidate_cases=120,           # how many candidate cases from page hits\n","    top_pages_show=12,             # how many top evidence pages to print\n","    top_cases_show=5,              # final top-k cases\n","    pages_per_case_for_context=2,  # #evidence pages per case to OCR for LLM\n","    max_context_chars=4000         # char budget for LLM context (roughly ~600–900 tokens)\n",")\n","\n","\n","# Optional sanity checks\n","try:\n","    info_pages = client.get_collection(COLLECTION_PAGES)\n","    info_cases = client.get_collection(COLLECTION_CASES)\n","    print(\"[ok] Qdrant connected\")\n","    print(\"[ok] pages:\", info_pages.status, \"| cases:\", info_cases.status)\n","except Exception as e:\n","    print(\"[warn]\", e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5Sy6KXVbcG-","executionInfo":{"status":"ok","timestamp":1761733346899,"user_tz":-420,"elapsed":346,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"d159271c-8aef-4c69-8568-8abcb6bd7a5b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[ok] Qdrant connected\n","[ok] pages: green | cases: green\n"]}]},{"cell_type":"markdown","source":["## Helpers (encoder + pretty printers)"],"metadata":{"id":"fg5HybzngiRz"}},{"cell_type":"code","source":["\n","\n","def encode_query_topk(q: str, top_m: int = 12):\n","    \"\"\"Encode a query with ColPali into a multi-vector and keep top_m sub-vectors to reduce noise and latency.\"\"\"\n","    subvecs = embed_queries(model, processor, device, [q])[0]\n","    return subvecs[:top_m]\n","\n","def print_page_hits(hits, title=None, limit=None):\n","    \"\"\"Pretty-print page-level hits.\"\"\"\n","    if title: print(title)\n","    for i, h in enumerate(hits[:(limit or len(hits))], 1):\n","        p = h.payload or {}\n","        print(f\"Rank {i:>2} | score={h.score:.3f} | case_id={p.get('case_id')} | page={p.get('page_number')} | {p.get('path')}\")\n","\n","def print_case_hits(hits, title=None):\n","    \"\"\"Pretty-print case-level hits.\"\"\"\n","    if title: print(title)\n","    for i, h in enumerate(hits, 1):\n","        p = h.payload or {}\n","        print(f\"Rank {i:>2} | score={h.score:.3f} | case_id={p.get('case_id')} | {p.get('case_title')}\")\n"],"metadata":{"id":"uFFO172PbrT0","executionInfo":{"status":"ok","timestamp":1761733351446,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## Page-level retrieval (MAX fusion over multivectors)"],"metadata":{"id":"K9Ae5Uz1gzsp"}},{"cell_type":"code","source":["def search_pages_MAX(\n","    question: str,\n","    k_pages: int = 100,\n","    m_query: int = DEFAULTS[\"page_m_query\"],\n","    per_subvec_limit: int = DEFAULTS[\"page_per_subvec_limit\"],\n","    hnsw_ef: int = DEFAULTS[\"page_hnsw_ef\"]\n","):\n","    \"\"\"\n","    Page-level retrieval with ColPali multivectors on a MAX-SIM collection.\n","    We query each sub-vector separately, take top-N page hits per sub-vector, and\n","    aggregate with MAX score per page (mimicking MAX comparator behavior).\n","    \"\"\"\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    try:\n","        params = models.SearchParams(hnsw_ef=hnsw_ef)  # may be ignored by older clients\n","    except Exception:\n","        params = None\n","\n","    agg = {}  # page_point_id -> (max_score, payload)\n","    for v in subvecs:\n","        hits = client.search(  # deprecated warning is fine; your client still supports it\n","            collection_name=COLLECTION_PAGES,\n","            query_vector=v,    # unnamed vector for unnamed multivector collections\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k_pages]\n","    return [type(\"Hit\", (), {\"id\": pid, \"score\": sc, \"payload\": pl}) for pid,(sc,pl) in ranked]\n"],"metadata":{"id":"NR2iovdrcHkf","executionInfo":{"status":"ok","timestamp":1761733354332,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Aggregate pages → cases (PAGE→CASE) + (optional) Fusion"],"metadata":{"id":"JLSEPjaMg04x"}},{"cell_type":"code","source":["def pages_to_case_candidates(hits_pages, top_cases=DEFAULTS[\"candidate_cases\"]):\n","    \"\"\"\n","    From page hits, compute candidate cases by taking the best page score per case,\n","    then keep top-N cases as candidates for a second-stage (optional) case-level search.\n","    \"\"\"\n","    case_best = {}\n","    for h in hits_pages:\n","        p = h.payload or {}\n","        cid = p.get(\"case_id\")\n","        if cid is None:\n","            continue\n","        ttl = p.get(\"case_title\", \"\")\n","        if cid not in case_best or h.score > case_best[cid][0]:\n","            case_best[cid] = (h.score, ttl)\n","    ranked = sorted(case_best.items(), key=lambda kv: kv[1][0], reverse=True)[:top_cases]\n","    return [int(cid) for cid, _ in ranked]\n","\n","def rank_cases_from_pages(hits_pages, top_k=DEFAULTS[\"top_cases_show\"]):\n","    \"\"\"\n","    Pure PAGE→CASE ranking: score(case) = max_page_score(case).\n","    This preserves page evidence—recommended for clinical QA with citations.\n","    \"\"\"\n","    case_best = {}\n","    for h in hits_pages:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        ttl = p.get(\"case_title\", \"\")\n","        if cid not in case_best or h.score > case_best[cid][0]:\n","            case_best[cid] = (h.score, ttl)\n","    ranked = sorted(case_best.items(), key=lambda kv: kv[1][0], reverse=True)[:top_k]\n","    return [type(\"Hit\", (), {\"id\": cid, \"score\": sc, \"payload\": {\"case_id\": cid, \"case_title\": ttl}})\n","            for cid,(sc,ttl) in ranked]\n","\n","def search_cases_MAX_with_candidates(\n","    question: str,\n","    candidate_case_ids: list[int],\n","    k: int = DEFAULTS[\"top_cases_show\"],\n","    m_query: int = DEFAULTS[\"case_m_query\"],\n","    per_subvec_limit: int = DEFAULTS[\"case_per_subvec_limit\"],\n","    hnsw_ef: int = DEFAULTS[\"case_hnsw_ef\"]\n","):\n","    \"\"\"\n","    Optional second-stage case-level re-ranking within candidate cases using MAX fusion.\n","    Useful if you want a hybrid score (page + case).\n","    \"\"\"\n","    if not candidate_case_ids:\n","        return []\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    try:\n","        params = models.SearchParams(hnsw_ef=hnsw_ef)\n","    except Exception:\n","        params = None\n","\n","    qfilter = models.Filter(should=[\n","        models.FieldCondition(key=\"case_id\", match=models.MatchValue(value=int(cid)))\n","        for cid in candidate_case_ids\n","    ])\n","\n","    agg = {}  # case_point_id -> (max_score, payload)\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_CASES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:k]\n","    return [type(\"Hit\", (), {\"id\": i, \"score\": sc, \"payload\": pl}) for i,(sc,pl) in ranked]\n","\n","def fuse_cases(page_hits, case_hits, w_page=0.75, w_case=0.25, top_k=DEFAULTS[\"top_cases_show\"]):\n","    \"\"\"\n","    Hybrid fusion: final_score = w_page * max_page_score + w_case * case_level_score.\n","    Keeps page evidence while stabilizing with case-level signal.\n","    \"\"\"\n","    page_best = {}\n","    for h in page_hits:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        ttl = p.get(\"case_title\",\"\")\n","        if cid not in page_best or h.score > page_best[cid][0]:\n","            page_best[cid] = (h.score, ttl)\n","\n","    case_best = {}\n","    for h in case_hits:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        ttl = p.get(\"case_title\",\"\")\n","        if cid not in case_best or h.score > case_best[cid][0]:\n","            case_best[cid] = (h.score, ttl)\n","\n","    all_ids = set(page_best) | set(case_best)\n","    fused = []\n","    for cid in all_ids:\n","        ps = page_best.get(cid, (0.0, \"\"))[0]\n","        cs = case_best.get(cid, (0.0, \"\"))[0]\n","        ttl = (page_best.get(cid) or case_best.get(cid) or (0.0, \"\"))[1]\n","        fused.append((cid, w_page*ps + w_case*cs, ttl))\n","\n","    fused.sort(key=lambda x: x[1], reverse=True)\n","    return [type(\"Hit\", (), {\"id\": cid, \"score\": sc, \"payload\": {\"case_id\": cid, \"case_title\": ttl}})\n","            for cid,sc,ttl in fused[:top_k]]\n"],"metadata":{"id":"U8Jtt-CccJkF","executionInfo":{"status":"ok","timestamp":1761733355898,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Get best evidence pages per case (for OCR/LLM)"],"metadata":{"id":"Ryv7SiPehWVi"}},{"cell_type":"code","source":["def search_pages_in_case(\n","    question: str,\n","    case_id: int,\n","    top_pages: int = 3,\n","    m_query: int = DEFAULTS[\"page_m_query\"],\n","    per_subvec_limit: int = DEFAULTS[\"page_per_subvec_limit\"],\n","    hnsw_ef: int = DEFAULTS[\"page_hnsw_ef\"]\n","):\n","    \"\"\"\n","    Retrieve the best evidence pages within a specific case_id.\n","    Useful to assemble citations and OCR text for the LLM.\n","    \"\"\"\n","    subvecs = encode_query_topk(question, top_m=m_query)\n","    try:\n","        params = models.SearchParams(hnsw_ef=hnsw_ef)\n","    except Exception:\n","        params = None\n","\n","    qfilter = models.Filter(must=[\n","        models.FieldCondition(key=\"case_id\", match=models.MatchValue(value=int(case_id)))\n","    ])\n","\n","    agg = {}  # page_point_id -> (max_score, payload)\n","    for v in subvecs:\n","        hits = client.search(\n","            collection_name=COLLECTION_PAGES,\n","            query_vector=v,\n","            limit=per_subvec_limit,\n","            with_payload=True,\n","            query_filter=qfilter,\n","            search_params=params\n","        )\n","        for h in hits:\n","            pid, sc, pl = h.id, h.score, h.payload\n","            if pid not in agg or sc > agg[pid][0]:\n","                agg[pid] = (sc, pl)\n","\n","    ranked = sorted(agg.items(), key=lambda kv: kv[1][0], reverse=True)[:top_pages]\n","\n","    # Normalize payload for OCR convenience\n","    out = []\n","    for pid,(sc,pl) in ranked:\n","        out.append({\n","            \"id\": pid,\n","            \"score\": float(sc),\n","            \"case_id\": int(pl.get(\"case_id\")),\n","            \"case_title\": pl.get(\"case_title\",\"\"),\n","            \"page_number\": pl.get(\"page_number\"),\n","            \"path\": pl.get(\"path\") or (pl.get(\"page_paths\") or [None])[0]\n","        })\n","    return out\n"],"metadata":{"id":"DK0tPRBJcWJz","executionInfo":{"status":"ok","timestamp":1761733358931,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## OCR & build context text for the LLM"],"metadata":{"id":"wFwnZ2ztha_l"}},{"cell_type":"code","source":["import re\n","from PIL import Image\n","import pytesseract\n","\n","def clean_text(s: str) -> str:\n","    \"\"\"Basic cleanup for OCR output: de-hyphen, collapse whitespace, normalize line breaks.\"\"\"\n","    s = re.sub(r'-\\n', '', s)\n","    s = re.sub(r'[ \\t]+\\n', '\\n', s)\n","    s = re.sub(r'\\n{2,}', '\\n\\n', s)\n","    return s.strip()\n","\n","def ocr_image_page(path: str, lang=\"eng\") -> str:\n","    \"\"\"OCR a page image (PNG/JPG) and return cleaned text.\"\"\"\n","    img = Image.open(path)\n","    txt = pytesseract.image_to_string(img, lang=lang)\n","    return clean_text(txt)\n","\n","def build_context_from_pages(pages: list[dict], max_chars: int = DEFAULTS[\"max_context_chars\"]) -> tuple[str, list[dict]]:\n","    \"\"\"\n","    Build a compact textual CONTEXT for the LLM:\n","    - pages: list of dicts with {case_id, case_title, page_number, path, score}\n","    - returns (context_text, contexts_meta_for_logging)\n","    \"\"\"\n","    ctx_blocks, meta = [], []\n","    total = 0\n","    for p in pages:\n","        text = ocr_image_page(p[\"path\"])\n","        if not text:\n","            continue\n","        header = f\"[Case {p['case_id']} | {p.get('case_title','')} | page {p['page_number']} | score {p['score']:.3f}]\"\n","        block = f\"{header}\\n{text}\"\n","        if total + len(block) > max_chars:\n","            break\n","        ctx_blocks.append(block)\n","        meta.append({\n","            \"case_id\": p[\"case_id\"], \"case_title\": p.get(\"case_title\",\"\"),\n","            \"page_number\": p[\"page_number\"], \"path\": p[\"path\"], \"score\": p[\"score\"],\n","            \"snippet\": text[:300]\n","        })\n","        total += len(block)\n","    return \"\\n\\n\".join(ctx_blocks), meta\n"],"metadata":{"id":"nqy8z4JDcYh9","executionInfo":{"status":"ok","timestamp":1761733361425,"user_tz":-420,"elapsed":9,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## End-to-End helper (query → pages → cases → context)"],"metadata":{"id":"oZUmkVHJhivS"}},{"cell_type":"code","source":["def retrieve_e2e(\n","    question: str,\n","    pages_per_case_for_context: int = DEFAULTS[\"pages_per_case_for_context\"],\n","    use_fusion: bool = False,   # False: PAGE→CASE only; True: Fusion (PAGE+CASE)\n","    show_intermediate: bool = True\n","):\n","    # Stage-1: page-level (broad)\n","    page_hits = search_pages_MAX(\n","        question,\n","        k_pages=max(DEFAULTS[\"top_pages_show\"], DEFAULTS[\"candidate_cases\"]),\n","        m_query=DEFAULTS[\"page_m_query\"],\n","        per_subvec_limit=DEFAULTS[\"page_per_subvec_limit\"],\n","        hnsw_ef=DEFAULTS[\"page_hnsw_ef\"]\n","    )\n","    if show_intermediate:\n","        print_page_hits(page_hits, title=\"\\n=== Top pages (evidence) ===\", limit=DEFAULTS[\"top_pages_show\"])\n","\n","    # Collect candidate case_ids from best page scores\n","    candidates = pages_to_case_candidates(page_hits, top_cases=DEFAULTS[\"candidate_cases\"])\n","    if show_intermediate:\n","        print(\"\\nCandidates (first 20):\", candidates[:20])\n","\n","    # Stage-2: case-level re-ranking (optional)\n","    if use_fusion:\n","        # Wide case-level search within candidates, then fuse with page scores\n","        case_hits_wide = search_cases_MAX_with_candidates(\n","            question,\n","            candidate_case_ids=candidates,\n","            k=DEFAULTS[\"candidate_cases\"],\n","            m_query=DEFAULTS[\"case_m_query\"],\n","            per_subvec_limit=DEFAULTS[\"case_per_subvec_limit\"],\n","            hnsw_ef=DEFAULTS[\"case_hnsw_ef\"]\n","        )\n","        final_cases = fuse_cases(page_hits, case_hits_wide, w_page=0.75, w_case=0.25, top_k=DEFAULTS[\"top_cases_show\"])\n","    else:\n","        # Pure PAGE→CASE ranking (recommended for strong page evidence)\n","        final_cases = rank_cases_from_pages(page_hits, top_k=DEFAULTS[\"top_cases_show\"])\n","\n","    print_case_hits(final_cases, title=\"\\n=== Final case hits ===\")\n","\n","    # Fetch best pages per final case (to feed OCR/LLM and show citations)\n","    pages_by_case = {}\n","    for h in final_cases:\n","        p = h.payload or {}\n","        cid = int(p[\"case_id\"])\n","        pages = search_pages_in_case(\n","            question, case_id=cid,\n","            top_pages=pages_per_case_for_context,\n","            m_query=DEFAULTS[\"page_m_query\"],\n","            per_subvec_limit=DEFAULTS[\"page_per_subvec_limit\"],\n","            hnsw_ef=DEFAULTS[\"page_hnsw_ef\"]\n","        )\n","        pages_by_case[cid] = pages\n","        print(f\"\\n--- Best pages for case_id={cid} ---\")\n","        for j, pg in enumerate(pages, 1):\n","            print(f\"  p{j} | score={pg['score']:.3f} | {pg['path']}\")\n","\n","    # Build the LLM context from the selected pages (ordered by final cases)\n","    ranked_pages_for_ctx = []\n","    for h in final_cases:\n","        cid = int((h.payload or {}).get(\"case_id\"))\n","        ranked_pages_for_ctx.extend(pages_by_case.get(cid, []))\n","\n","    context_text, contexts_meta = build_context_from_pages(\n","        ranked_pages_for_ctx, max_chars=DEFAULTS[\"max_context_chars\"]\n","    )\n","    print(f\"\\n[context chars] {len(context_text)}\")\n","\n","    return dict(\n","        page_hits=page_hits,\n","        final_cases=final_cases,\n","        pages_by_case=pages_by_case,\n","        context_text=context_text,\n","        contexts_meta=contexts_meta\n","    )\n"],"metadata":{"id":"S-uOV-5Th3i-","executionInfo":{"status":"ok","timestamp":1761734002563,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Example query (Ebola)"],"metadata":{"id":"iAOqjKKWh5jm"}},{"cell_type":"code","source":["question = (\n","  \"Ebola virus disease: hemorrhagic fever with bleeding and shock; \"\n","  \"nursing isolation, PPE and contact precautions; patient from Sudan.\"\n",")\n","\n","result = retrieve_e2e(\n","    question,\n","    pages_per_case_for_context=DEFAULTS[\"pages_per_case_for_context\"],\n","    use_fusion=False,   # set True to combine PAGE and CASE signals\n","    show_intermediate=True\n",")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoSJ2CCcckbs","executionInfo":{"status":"ok","timestamp":1761734660195,"user_tz":-420,"elapsed":33823,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"e07fe211-4ca1-43be-874b-dc7244e475b2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3348236797.py:21: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  hits = client.search(  # deprecated warning is fine; your client still supports it\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Top pages (evidence) ===\n","Rank  1 | score=0.371 | case_id=60 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/60---A-6-Year-Old-Boy-from-Malawi-With-Proptos_2022_Clinical-Cases-in-Tropic_page_2.png\n","Rank  2 | score=0.369 | case_id=84 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/84---A-64-Year-Old-Japanese-Man-With-Generalize_2022_Clinical-Cases-in-Tropi_page_2.png\n","Rank  3 | score=0.363 | case_id=76 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/76---A-55-Year-Old-Woman-from-Turkey-With-Feve_2022_Clinical-Cases-in-Tropic_page_2.png\n","Rank  4 | score=0.358 | case_id=2 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/2---A-7-Year-Old-Girl-from-Peru-With-a-Chron_2022_Clinical-Cases-in-Tropical_page_2.png\n","Rank  5 | score=0.349 | case_id=55 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/55---A-40-Year-Old-Male-Farmer-from-Peru-With-Ch_2022_Clinical-Cases-in-Trop_page_2.png\n","Rank  6 | score=0.342 | case_id=11 | page=3 | /content/drive/MyDrive/Project-AI/PDF-Data/11---A-45-Year-Old-Male-Security-Guard-from-Malawi-_2022_Clinical-Cases-in-T_page_3.png\n","Rank  7 | score=0.342 | case_id=90 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/90---A-55-Year-Old-Couple-Both-Returning-from-Chile-a_2022_Clinical-Cases-in_page_2.png\n","Rank  8 | score=0.342 | case_id=54 | page=1 | /content/drive/MyDrive/Project-AI/PDF-Data/54---A-52-Year-Old-Male-Safari-Tourist-Returning-fro_2022_Clinical-Cases-in-_page_1.png\n","Rank  9 | score=0.340 | case_id=62 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/62---A-28-Year-Old-Man-from-Ghana-With-a-Chron_2022_Clinical-Cases-in-Tropic_page_2.png\n","Rank 10 | score=0.339 | case_id=5 | page=2 | /content/drive/MyDrive/Project-AI/PDF-Data/5---A-4-Year-Old-Boy-from-Laos-With-a-Lesion-o_2022_Clinical-Cases-in-Tropic_page_2.png\n","Rank 11 | score=0.338 | case_id=33 | page=1 | /content/drive/MyDrive/Project-AI/PDF-Data/33---A-53-Year-Old-Man-from-Malawi-With-a-C_2022_Clinical-Cases-in-Tropical-_page_1.png\n","Rank 12 | score=0.337 | case_id=92 | page=3 | /content/drive/MyDrive/Project-AI/PDF-Data/92---A-42-Year-Old-Traveller-Returning-from-Thaila_2022_Clinical-Cases-in-Tr_page_3.png\n","\n","Candidates (first 20): [60, 84, 76, 2, 55, 11, 90, 54, 62, 5, 33, 92, 50, 59, 32, 40, 88, 67, 71, 34]\n","\n","=== Final case hits ===\n","Rank  1 | score=0.371 | case_id=60 | 60 A 6 Year Old Boy from Malawi With Proptos 2022 Clinical Cases in Tropic\n","Rank  2 | score=0.369 | case_id=84 | 84 A 64 Year Old Japanese Man With Generalize 2022 Clinical Cases in Tropi\n","Rank  3 | score=0.363 | case_id=76 | 76 A 55 Year Old Woman from Turkey With Feve 2022 Clinical Cases in Tropic\n","Rank  4 | score=0.358 | case_id=2 | 2 A 7 Year Old Girl from Peru With a Chron 2022 Clinical Cases in Tropical\n","Rank  5 | score=0.349 | case_id=55 | 55 A 40 Year Old Male Farmer from Peru With Ch 2022 Clinical Cases in Trop\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1356378198.py:25: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n","  hits = client.search(\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Best pages for case_id=60 ---\n","  p1 | score=0.371 | /content/drive/MyDrive/Project-AI/PDF-Data/60---A-6-Year-Old-Boy-from-Malawi-With-Proptos_2022_Clinical-Cases-in-Tropic_page_2.png\n","  p2 | score=0.218 | /content/drive/MyDrive/Project-AI/PDF-Data/60---A-6-Year-Old-Boy-from-Malawi-With-Proptos_2022_Clinical-Cases-in-Tropic_page_1.png\n","\n","--- Best pages for case_id=84 ---\n","  p1 | score=0.369 | /content/drive/MyDrive/Project-AI/PDF-Data/84---A-64-Year-Old-Japanese-Man-With-Generalize_2022_Clinical-Cases-in-Tropi_page_2.png\n","  p2 | score=0.294 | /content/drive/MyDrive/Project-AI/PDF-Data/84---A-64-Year-Old-Japanese-Man-With-Generalize_2022_Clinical-Cases-in-Tropi_page_3.png\n","\n","--- Best pages for case_id=76 ---\n","  p1 | score=0.363 | /content/drive/MyDrive/Project-AI/PDF-Data/76---A-55-Year-Old-Woman-from-Turkey-With-Feve_2022_Clinical-Cases-in-Tropic_page_2.png\n","  p2 | score=0.262 | /content/drive/MyDrive/Project-AI/PDF-Data/76---A-55-Year-Old-Woman-from-Turkey-With-Feve_2022_Clinical-Cases-in-Tropic_page_1.png\n","\n","--- Best pages for case_id=2 ---\n","  p1 | score=0.358 | /content/drive/MyDrive/Project-AI/PDF-Data/2---A-7-Year-Old-Girl-from-Peru-With-a-Chron_2022_Clinical-Cases-in-Tropical_page_2.png\n","  p2 | score=0.310 | /content/drive/MyDrive/Project-AI/PDF-Data/2---A-7-Year-Old-Girl-from-Peru-With-a-Chron_2022_Clinical-Cases-in-Tropical_page_3.png\n","\n","--- Best pages for case_id=55 ---\n","  p1 | score=0.349 | /content/drive/MyDrive/Project-AI/PDF-Data/55---A-40-Year-Old-Male-Farmer-from-Peru-With-Ch_2022_Clinical-Cases-in-Trop_page_2.png\n","  p2 | score=0.305 | /content/drive/MyDrive/Project-AI/PDF-Data/55---A-40-Year-Old-Male-Farmer-from-Peru-With-Ch_2022_Clinical-Cases-in-Trop_page_3.png\n","\n","[context chars] 3847\n"]}]},{"cell_type":"code","source":["import os\n","\n","# In ra current working directory\n","print(\"Current working directory:\", os.getcwd())\n","\n","# In ra tất cả các file trong thư mục hiện tại\n","!ls -al\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKFZKwlY_mZN","executionInfo":{"status":"ok","timestamp":1761741795112,"user_tz":-420,"elapsed":114,"user":{"displayName":"Nhan Nguyen Thanh","userId":"08925512626420686133"}},"outputId":"332a3330-2f97-4c90-f643-36ff03c2fcb1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content\n","total 16\n","drwxr-xr-x 1 root root 4096 Oct 27 13:37 .\n","drwxr-xr-x 1 root root 4096 Oct 29 12:32 ..\n","drwxr-xr-x 4 root root 4096 Oct 27 13:37 .config\n","drwxr-xr-x 1 root root 4096 Oct 27 13:37 sample_data\n"]}]}]}